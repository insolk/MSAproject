[2021-04-17 16:00:05,671] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:00:05,684] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:00:15,688] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:00:15,689] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:00:25,694] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:00:25,696] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:00:35,702] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:00:35,703] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:00:45,709] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:00:45,710] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:00:55,716] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:00:55,717] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:01:05,719] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:01:05,720] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:01:15,722] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:01:15,723] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:01:16,947] INFO Successfully processed removal of connector 'signin-connect' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:578)
[2021-04-17 16:01:16,952] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector signin-connect config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1521)
[2021-04-17 16:01:16,953] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling connector-only config update by stopping connector signin-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:593)
[2021-04-17 16:01:16,953] INFO Stopping connector signin-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-17 16:01:16,953] INFO Scheduled shutdown for WorkerConnector{id=signin-connect} (org.apache.kafka.connect.runtime.WorkerConnector:249)
[2021-04-17 16:01:16,954] INFO Completed shutdown for WorkerConnector{id=signin-connect} (org.apache.kafka.connect.runtime.WorkerConnector:269)
[2021-04-17 16:01:16,957] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-17 16:01:16,957] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-17 16:01:16,961] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=6, memberId='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-17 16:01:16,968] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=6, memberId='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-17 16:01:16,970] INFO Stopping connector signin-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-17 16:01:16,970] INFO Stopping task signin-connect-0 (org.apache.kafka.connect.runtime.Worker:836)
[2021-04-17 16:01:16,970] WARN Ignoring stop request for unowned connector signin-connect (org.apache.kafka.connect.runtime.Worker:390)
[2021-04-17 16:01:16,971] WARN Ignoring await stop request for non-present connector signin-connect (org.apache.kafka.connect.runtime.Worker:415)
[2021-04-17 16:01:16,974] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1767)
[2021-04-17 16:01:16,979] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1786)
[2021-04-17 16:01:16,983] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 6 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', leaderUrl='http://192.168.0.20:8083/', offset=9, connectorIds=[signup-connect], taskIds=[signup-connect-0], revokedConnectorIds=[signin-connect], revokedTaskIds=[signin-connect-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-17 16:01:16,985] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 9 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-17 16:01:16,988] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-17 16:01:16,989] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-17 16:01:16,989] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-17 16:01:16,991] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=7, memberId='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-17 16:01:16,994] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=7, memberId='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-17 16:01:16,995] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 7 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', leaderUrl='http://192.168.0.20:8083/', offset=9, connectorIds=[signup-connect], taskIds=[signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-17 16:01:16,995] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 9 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-17 16:01:16,995] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-17 16:01:23,790] INFO Successfully processed removal of connector 'signup-connect' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:578)
[2021-04-17 16:01:23,792] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector signup-connect config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1521)
[2021-04-17 16:01:23,792] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling connector-only config update by stopping connector signup-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:593)
[2021-04-17 16:01:23,792] INFO Stopping connector signup-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-17 16:01:23,792] INFO Scheduled shutdown for WorkerConnector{id=signup-connect} (org.apache.kafka.connect.runtime.WorkerConnector:249)
[2021-04-17 16:01:23,792] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:176)
[2021-04-17 16:01:23,793] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2021-04-17 16:01:23,793] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-17 16:01:23,794] INFO Completed shutdown for WorkerConnector{id=signup-connect} (org.apache.kafka.connect.runtime.WorkerConnector:269)
[2021-04-17 16:01:23,798] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-17 16:01:23,798] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-17 16:01:23,801] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=8, memberId='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-17 16:01:23,808] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=8, memberId='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-17 16:01:23,809] INFO Stopping task signup-connect-0 (org.apache.kafka.connect.runtime.Worker:836)
[2021-04-17 16:01:23,809] INFO Stopping connector signup-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-17 16:01:23,809] WARN Ignoring stop request for unowned connector signup-connect (org.apache.kafka.connect.runtime.Worker:390)
[2021-04-17 16:01:23,810] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:317)
[2021-04-17 16:01:23,810] WARN Ignoring await stop request for non-present connector signup-connect (org.apache.kafka.connect.runtime.Worker:415)
[2021-04-17 16:01:23,842] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:324)
[2021-04-17 16:01:23,842] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-17 16:01:23,843] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:01:23,843] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:01:23,843] INFO [Producer clientId=connector-producer-signup-connect-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1205)
[2021-04-17 16:01:23,846] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-17 16:01:23,846] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-17 16:01:23,846] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-17 16:01:23,847] INFO App info kafka.producer for connector-producer-signup-connect-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-17 16:01:23,847] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1767)
[2021-04-17 16:01:23,851] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1786)
[2021-04-17 16:01:23,851] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 8 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', leaderUrl='http://192.168.0.20:8083/', offset=11, connectorIds=[], taskIds=[], revokedConnectorIds=[signup-connect], revokedTaskIds=[signup-connect-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-17 16:01:23,853] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 11 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-17 16:01:23,853] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-17 16:01:23,853] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-17 16:01:23,853] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-17 16:01:23,855] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=9, memberId='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-17 16:01:23,858] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=9, memberId='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-17 16:01:23,858] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 9 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', leaderUrl='http://192.168.0.20:8083/', offset=11, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-17 16:01:23,858] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 11 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-17 16:01:23,858] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-17 16:01:32,348] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:361)
[2021-04-17 16:01:32,354] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector signup-connect config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1534)
[2021-04-17 16:01:32,355] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-17 16:01:32,355] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-17 16:01:32,356] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=10, memberId='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-17 16:01:32,363] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=10, memberId='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-17 16:01:32,363] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 10 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', leaderUrl='http://192.168.0.20:8083/', offset=12, connectorIds=[signup-connect], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-17 16:01:32,364] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 12 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-17 16:01:32,364] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector signup-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1299)
[2021-04-17 16:01:32,364] INFO Creating connector signup-connect of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:274)
[2021-04-17 16:01:32,365] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signup-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-17 16:01:32,365] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signup-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-17 16:01:32,368] INFO Instantiated connector signup-connect with version 10.1.0 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:284)
[2021-04-17 16:01:32,368] INFO Finished creating connector signup-connect (org.apache.kafka.connect.runtime.Worker:310)
[2021-04-17 16:01:32,368] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2021-04-17 16:01:32,368] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-17 16:01:32,369] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [users]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.initial = null
	topic.prefix = my_topic_
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:361)
[2021-04-17 16:01:32,370] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-17 16:01:32,378] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2021-04-17 16:01:32,380] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signup-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-17 16:01:32,380] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signup-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-17 16:01:32,872] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [signup-connect-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1549)
[2021-04-17 16:01:32,872] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling task config update by restarting tasks [] (org.apache.kafka.connect.runtime.distributed.DistributedHerder:647)
[2021-04-17 16:01:32,872] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-17 16:01:32,872] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-17 16:01:32,874] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=11, memberId='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-17 16:01:32,876] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=11, memberId='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-17 16:01:32,876] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 11 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', leaderUrl='http://192.168.0.20:8083/', offset=14, connectorIds=[signup-connect], taskIds=[signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-17 16:01:32,876] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 14 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-17 16:01:32,876] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task signup-connect-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1258)
[2021-04-17 16:01:32,876] INFO Creating task signup-connect-0 (org.apache.kafka.connect.runtime.Worker:509)
[2021-04-17 16:01:32,877] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signup-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-04-17 16:01:32,877] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signup-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-17 16:01:32,877] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-04-17 16:01:32,878] INFO Instantiated task signup-connect-0 with version 10.1.0 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-04-17 16:01:32,878] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-17 16:01:32,878] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task signup-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:537)
[2021-04-17 16:01:32,882] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-17 16:01:32,882] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task signup-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:543)
[2021-04-17 16:01:32,882] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task signup-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-04-17 16:01:32,884] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signup-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-17 16:01:32,884] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signup-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-17 16:01:32,884] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:606)
[2021-04-17 16:01:32,885] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-signup-connect-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:361)
[2021-04-17 16:01:32,889] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-17 16:01:32,890] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-17 16:01:32,890] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-17 16:01:32,890] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-17 16:01:32,890] INFO Kafka startTimeMs: 1618642892890 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-17 16:01:32,893] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-17 16:01:32,900] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:85)
[2021-04-17 16:01:32,902] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [users]
	tables = [`potato`.`users`]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.initial = null
	topic.prefix = my_topic_
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:361)
[2021-04-17 16:01:32,904] INFO Using JDBC dialect MySql (io.confluent.connect.jdbc.source.JdbcSourceTask:102)
[2021-04-17 16:01:32,905] INFO [Producer clientId=connector-producer-signup-connect-0] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-17 16:01:33,034] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-17 16:01:33,063] INFO Found offset {{table=users}=null, {protocol=1, table=potato.users}={incrementing=2}} for partition {protocol=1, table=potato.users} (io.confluent.connect.jdbc.source.JdbcSourceTask:193)
[2021-04-17 16:01:33,064] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:261)
[2021-04-17 16:01:33,065] INFO WorkerSourceTask{id=signup-connect-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:233)
[2021-04-17 16:01:33,066] INFO Begin using SQL query: SELECT * FROM `potato`.`users` WHERE `potato`.`users`.`id` > ? ORDER BY `potato`.`users`.`id` ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2021-04-17 16:01:42,899] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:01:42,902] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:01:43,599] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:361)
[2021-04-17 16:01:43,614] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector signin-connect config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1534)
[2021-04-17 16:01:44,119] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-17 16:01:44,119] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-17 16:01:44,122] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=12, memberId='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-17 16:01:44,131] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=12, memberId='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-17 16:01:44,132] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 12 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', leaderUrl='http://192.168.0.20:8083/', offset=15, connectorIds=[signin-connect, signup-connect], taskIds=[signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-17 16:01:44,133] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 15 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-17 16:01:44,134] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector signin-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1299)
[2021-04-17 16:01:44,135] INFO Creating connector signin-connect of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:274)
[2021-04-17 16:01:44,137] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signin-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-17 16:01:44,137] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signin-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-17 16:01:44,142] INFO Instantiated connector signin-connect with version 10.1.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:284)
[2021-04-17 16:01:44,142] INFO Finished creating connector signin-connect (org.apache.kafka.connect.runtime.Worker:310)
[2021-04-17 16:01:44,142] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-17 16:01:44,143] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signin-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-17 16:01:44,143] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signin-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-17 16:01:44,143] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2021-04-17 16:01:44,640] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [signin-connect-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1549)
[2021-04-17 16:01:44,640] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling task config update by restarting tasks [] (org.apache.kafka.connect.runtime.distributed.DistributedHerder:647)
[2021-04-17 16:01:44,640] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-17 16:01:44,640] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-17 16:01:44,641] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=13, memberId='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-17 16:01:44,645] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=13, memberId='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-17 16:01:44,645] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 13 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1', leaderUrl='http://192.168.0.20:8083/', offset=17, connectorIds=[signin-connect, signup-connect], taskIds=[signin-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-17 16:01:44,646] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 17 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-17 16:01:44,646] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task signin-connect-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1258)
[2021-04-17 16:01:44,646] INFO Creating task signin-connect-0 (org.apache.kafka.connect.runtime.Worker:509)
[2021-04-17 16:01:44,649] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signin-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-04-17 16:01:44,649] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signin-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-17 16:01:44,649] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-04-17 16:01:44,650] INFO Instantiated task signin-connect-0 with version 10.1.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-04-17 16:01:44,652] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-17 16:01:44,652] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task signin-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:537)
[2021-04-17 16:01:44,652] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-17 16:01:44,652] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task signin-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:543)
[2021-04-17 16:01:44,652] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task signin-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-04-17 16:01:44,654] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-04-17 16:01:44,654] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signin-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-17 16:01:44,654] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signin-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-17 16:01:44,655] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-signin-connect-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-signin-connect
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-04-17 16:01:44,668] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-17 16:01:44,668] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-17 16:01:44,668] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-17 16:01:44,669] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-17 16:01:44,669] INFO Kafka startTimeMs: 1618642904668 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-17 16:01:44,671] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-17 16:01:44,672] INFO [Consumer clientId=connector-consumer-signin-connect-0, groupId=connect-signin-connect] Subscribed to topic(s): my_topic_users (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-04-17 16:01:44,672] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:48)
[2021-04-17 16:01:44,672] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:361)
[2021-04-17 16:01:44,673] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-17 16:01:44,673] INFO WorkerSinkTask{id=signin-connect-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-04-17 16:01:44,686] INFO [Consumer clientId=connector-consumer-signin-connect-0, groupId=connect-signin-connect] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-17 16:01:44,687] INFO [Consumer clientId=connector-consumer-signin-connect-0, groupId=connect-signin-connect] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-04-17 16:01:44,688] INFO [Consumer clientId=connector-consumer-signin-connect-0, groupId=connect-signin-connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-17 16:01:44,692] INFO [Consumer clientId=connector-consumer-signin-connect-0, groupId=connect-signin-connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-17 16:01:44,694] INFO [Consumer clientId=connector-consumer-signin-connect-0, groupId=connect-signin-connect] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-signin-connect-0-09666807-dbdb-46f3-b22a-f9782ab549f8', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-17 16:01:44,694] INFO [Consumer clientId=connector-consumer-signin-connect-0, groupId=connect-signin-connect] Finished assignment for group at generation 3: {connector-consumer-signin-connect-0-09666807-dbdb-46f3-b22a-f9782ab549f8=Assignment(partitions=[my_topic_users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2021-04-17 16:01:44,697] INFO [Consumer clientId=connector-consumer-signin-connect-0, groupId=connect-signin-connect] Successfully synced group in generation Generation{generationId=3, memberId='connector-consumer-signin-connect-0-09666807-dbdb-46f3-b22a-f9782ab549f8', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-17 16:01:44,697] INFO [Consumer clientId=connector-consumer-signin-connect-0, groupId=connect-signin-connect] Notifying assignor about the new Assignment(partitions=[my_topic_users-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-04-17 16:01:44,698] INFO [Consumer clientId=connector-consumer-signin-connect-0, groupId=connect-signin-connect] Adding newly assigned partitions: my_topic_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-04-17 16:01:44,699] INFO [Consumer clientId=connector-consumer-signin-connect-0, groupId=connect-signin-connect] Found no committed offset for partition my_topic_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1354)
[2021-04-17 16:01:44,704] INFO [Consumer clientId=connector-consumer-signin-connect-0, groupId=connect-signin-connect] Resetting offset for partition my_topic_users-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-17 16:01:44,728] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-17 16:01:44,740] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-17 16:01:44,744] INFO Checking MySql dialect for existence of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-17 16:01:44,754] INFO Using MySql dialect TABLE "my_topic_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-17 16:01:44,767] INFO Checking MySql dialect for type of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-17 16:01:44,779] INFO Setting metadata for table "my_topic_users" to Table{name='"my_topic_users"', type=TABLE columns=[Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-17 16:01:44,787] WARN Write of 6 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-17 16:01:44,790] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-17 16:01:44,793] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-17 16:01:44,793] ERROR WorkerSinkTask{id=signin-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-17 16:01:47,800] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-17 16:01:47,847] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-17 16:01:47,856] INFO Checking MySql dialect for existence of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-17 16:01:47,875] INFO Using MySql dialect TABLE "my_topic_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-17 16:01:47,907] INFO Checking MySql dialect for type of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-17 16:01:47,920] INFO Setting metadata for table "my_topic_users" to Table{name='"my_topic_users"', type=TABLE columns=[Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-17 16:01:47,938] WARN Write of 6 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-17 16:01:47,941] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-17 16:01:47,945] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-17 16:01:47,945] ERROR WorkerSinkTask{id=signin-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-17 16:01:50,953] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-17 16:01:50,979] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-17 16:01:50,983] INFO Checking MySql dialect for existence of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-17 16:01:50,990] INFO Using MySql dialect TABLE "my_topic_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-17 16:01:50,999] INFO Checking MySql dialect for type of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-17 16:01:51,002] INFO Setting metadata for table "my_topic_users" to Table{name='"my_topic_users"', type=TABLE columns=[Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-17 16:01:51,009] WARN Write of 6 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-17 16:01:51,010] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-17 16:01:51,011] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-17 16:01:51,011] ERROR WorkerSinkTask{id=signin-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-17 16:01:52,912] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:01:52,916] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:01:54,015] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-17 16:01:54,023] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-17 16:01:54,029] INFO Checking MySql dialect for existence of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-17 16:01:54,034] INFO Using MySql dialect TABLE "my_topic_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-17 16:01:54,044] INFO Checking MySql dialect for type of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-17 16:01:54,048] INFO Setting metadata for table "my_topic_users" to Table{name='"my_topic_users"', type=TABLE columns=[Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-17 16:01:54,051] WARN Write of 6 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-17 16:01:54,052] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-17 16:01:54,052] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-17 16:01:54,052] ERROR WorkerSinkTask{id=signin-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-17 16:01:54,671] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-17 16:01:54,676] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-17 16:01:54,680] INFO Checking MySql dialect for existence of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-17 16:01:54,687] INFO Using MySql dialect TABLE "my_topic_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-17 16:01:54,698] INFO Checking MySql dialect for type of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-17 16:01:54,700] INFO Setting metadata for table "my_topic_users" to Table{name='"my_topic_users"', type=TABLE columns=[Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-17 16:01:54,705] WARN Write of 6 records failed, remainingRetries=6 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-17 16:01:54,705] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-17 16:01:54,706] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-17 16:01:54,706] ERROR WorkerSinkTask{id=signin-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-17 16:01:57,710] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-17 16:01:57,724] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-17 16:01:57,731] INFO Checking MySql dialect for existence of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-17 16:01:57,741] INFO Using MySql dialect TABLE "my_topic_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-17 16:01:57,756] INFO Checking MySql dialect for type of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-17 16:01:57,760] INFO Setting metadata for table "my_topic_users" to Table{name='"my_topic_users"', type=TABLE columns=[Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-17 16:01:57,763] WARN Write of 6 records failed, remainingRetries=5 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-17 16:01:57,764] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-17 16:01:57,764] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-17 16:01:57,764] ERROR WorkerSinkTask{id=signin-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-17 16:02:00,771] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-17 16:02:00,785] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-17 16:02:00,795] INFO Checking MySql dialect for existence of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-17 16:02:00,802] INFO Using MySql dialect TABLE "my_topic_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-17 16:02:00,807] INFO Checking MySql dialect for type of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-17 16:02:00,810] INFO Setting metadata for table "my_topic_users" to Table{name='"my_topic_users"', type=TABLE columns=[Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-17 16:02:00,822] WARN Write of 6 records failed, remainingRetries=4 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-17 16:02:00,823] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-17 16:02:00,823] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-17 16:02:00,823] ERROR WorkerSinkTask{id=signin-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-17 16:02:02,925] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:02:02,935] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:02:03,826] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-17 16:02:03,839] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-17 16:02:03,848] INFO Checking MySql dialect for existence of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-17 16:02:03,853] INFO Using MySql dialect TABLE "my_topic_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-17 16:02:03,864] INFO Checking MySql dialect for type of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-17 16:02:03,868] INFO Setting metadata for table "my_topic_users" to Table{name='"my_topic_users"', type=TABLE columns=[Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-17 16:02:03,872] WARN Write of 6 records failed, remainingRetries=3 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-17 16:02:03,873] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-17 16:02:03,875] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-17 16:02:03,875] ERROR WorkerSinkTask{id=signin-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-17 16:02:04,713] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-17 16:02:04,721] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-17 16:02:04,729] INFO Checking MySql dialect for existence of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-17 16:02:04,734] INFO Using MySql dialect TABLE "my_topic_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-17 16:02:04,746] INFO Checking MySql dialect for type of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-17 16:02:04,749] INFO Setting metadata for table "my_topic_users" to Table{name='"my_topic_users"', type=TABLE columns=[Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-17 16:02:04,755] WARN Write of 6 records failed, remainingRetries=2 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-17 16:02:04,756] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-17 16:02:04,757] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-17 16:02:04,758] ERROR WorkerSinkTask{id=signin-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-17 16:02:07,764] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-17 16:02:07,773] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-17 16:02:07,783] INFO Checking MySql dialect for existence of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-17 16:02:07,789] INFO Using MySql dialect TABLE "my_topic_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-17 16:02:07,800] INFO Checking MySql dialect for type of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-17 16:02:07,811] INFO Setting metadata for table "my_topic_users" to Table{name='"my_topic_users"', type=TABLE columns=[Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-17 16:02:07,816] WARN Write of 6 records failed, remainingRetries=1 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-17 16:02:07,817] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-17 16:02:07,818] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-17 16:02:07,818] ERROR WorkerSinkTask{id=signin-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-17 16:02:10,822] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-17 16:02:10,833] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-17 16:02:10,844] INFO Checking MySql dialect for existence of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-17 16:02:10,850] INFO Using MySql dialect TABLE "my_topic_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-17 16:02:10,860] INFO Checking MySql dialect for type of TABLE "my_topic_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-17 16:02:10,864] INFO Setting metadata for table "my_topic_users" to Table{name='"my_topic_users"', type=TABLE columns=[Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-17 16:02:10,867] WARN Write of 6 records failed, remainingRetries=0 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-17 16:02:10,868] ERROR Failing task after exhausting retries; encountered 2 exceptions on last write attempt. For complete details on each exception, please enable DEBUG logging. (io.confluent.connect.jdbc.sink.JdbcSinkTask:113)
[2021-04-17 16:02:10,868] ERROR WorkerSinkTask{id=signin-connect-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'
 (org.apache.kafka.connect.runtime.WorkerSinkTask:612)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:122)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-17 16:02:10,868] ERROR WorkerSinkTask{id=signin-connect-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:614)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:122)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	... 10 more
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '2' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '2' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-17 16:02:10,869] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:161)
[2021-04-17 16:02:10,869] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-17 16:02:10,871] INFO [Consumer clientId=connector-consumer-signin-connect-0, groupId=connect-signin-connect] Revoke previously assigned partitions my_topic_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2021-04-17 16:02:10,871] INFO [Consumer clientId=connector-consumer-signin-connect-0, groupId=connect-signin-connect] Member connector-consumer-signin-connect-0-09666807-dbdb-46f3-b22a-f9782ab549f8 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-04-17 16:02:10,885] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-17 16:02:10,885] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-17 16:02:10,885] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-17 16:02:10,892] INFO App info kafka.consumer for connector-consumer-signin-connect-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-17 16:02:12,940] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:02:12,942] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:02:22,949] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:02:22,950] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:02:32,956] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:02:32,957] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:02:42,959] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:02:42,960] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:02:52,966] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:02:52,967] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:03:02,971] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:03:02,973] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:03:12,975] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:03:12,977] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:03:22,980] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:03:22,981] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:03:32,986] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:03:32,989] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:03:42,994] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:03:42,995] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:03:53,000] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:03:53,002] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:04:03,005] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:04:03,006] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:04:13,015] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:04:13,016] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:04:23,018] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:04:23,019] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:04:33,024] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:04:33,025] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:04:43,034] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:04:43,035] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:04:53,041] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:04:53,042] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:05:03,051] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:05:03,057] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:05:13,063] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:05:13,064] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:05:23,070] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:05:23,070] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:05:33,071] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:05:33,072] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:05:43,078] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:05:43,078] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:05:53,082] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:05:53,083] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:06:03,088] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:06:03,089] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:06:13,095] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:06:13,098] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:06:23,104] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:06:23,105] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:06:33,110] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:06:33,113] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:06:43,116] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:06:43,117] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:06:53,123] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:06:53,125] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:07:03,127] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:07:03,128] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:07:13,133] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:07:13,134] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:07:23,136] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:07:23,137] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:07:33,137] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:07:33,138] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:07:43,144] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:07:43,145] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:07:53,151] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:07:53,152] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:08:03,155] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:08:03,156] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:08:13,158] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:08:13,159] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:08:23,160] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:08:23,161] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:08:33,167] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:08:33,168] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:08:43,173] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:08:43,175] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:08:53,178] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:08:53,179] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:09:03,185] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:09:03,186] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:09:13,187] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:09:13,189] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:09:23,194] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:09:23,196] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:09:33,198] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:09:33,198] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:09:43,203] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:09:43,204] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:09:53,208] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:09:53,210] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:10:03,223] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:10:03,224] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:10:13,227] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:10:13,228] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:10:23,233] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:10:23,234] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:10:33,247] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:10:33,249] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:10:43,256] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:10:43,257] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:10:53,264] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:10:53,264] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:11:03,266] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:11:03,267] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:11:13,272] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:11:13,274] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:11:23,280] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:11:23,281] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:11:33,283] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:11:33,284] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:11:43,290] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:11:43,292] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:11:53,293] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:11:53,294] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:12:02,109] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2021-04-17 16:12:02,109] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:327)
[2021-04-17 16:12:02,125] INFO Stopped http_8083@58cf8f94{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:381)
[2021-04-17 16:12:02,125] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2021-04-17 16:12:02,127] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:344)
[2021-04-17 16:12:02,127] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:682)
[2021-04-17 16:12:02,127] INFO [Worker clientId=connect-1, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:656)
[2021-04-17 16:12:02,128] INFO Stopping task signup-connect-0 (org.apache.kafka.connect.runtime.Worker:836)
[2021-04-17 16:12:02,128] INFO Stopping connector signup-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-17 16:12:02,128] INFO Stopping connector signin-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-17 16:12:02,129] INFO Stopping task signin-connect-0 (org.apache.kafka.connect.runtime.Worker:836)
[2021-04-17 16:12:02,129] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:317)
[2021-04-17 16:12:02,129] INFO Scheduled shutdown for WorkerConnector{id=signup-connect} (org.apache.kafka.connect.runtime.WorkerConnector:249)
[2021-04-17 16:12:02,129] INFO Scheduled shutdown for WorkerConnector{id=signin-connect} (org.apache.kafka.connect.runtime.WorkerConnector:249)
[2021-04-17 16:12:02,129] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:176)
[2021-04-17 16:12:02,129] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2021-04-17 16:12:02,130] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-17 16:12:02,138] INFO Completed shutdown for WorkerConnector{id=signin-connect} (org.apache.kafka.connect.runtime.WorkerConnector:269)
[2021-04-17 16:12:02,138] INFO Completed shutdown for WorkerConnector{id=signup-connect} (org.apache.kafka.connect.runtime.WorkerConnector:269)
[2021-04-17 16:12:02,143] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:324)
[2021-04-17 16:12:02,144] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-17 16:12:02,144] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-17 16:12:02,144] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-17 16:12:02,145] INFO [Producer clientId=connector-producer-signup-connect-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1205)
[2021-04-17 16:12:02,146] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-17 16:12:02,146] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-17 16:12:02,146] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-17 16:12:02,148] INFO App info kafka.producer for connector-producer-signup-connect-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-17 16:12:02,151] INFO [Worker clientId=connect-1, groupId=connect-cluster] Member connect-1-770fe3e9-1358-4c30-96ad-94e1f89565e1 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-04-17 16:12:02,151] WARN [Worker clientId=connect-1, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1010)
[2021-04-17 16:12:02,151] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-17 16:12:02,151] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-17 16:12:02,151] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-17 16:12:02,152] INFO App info kafka.connect for connect-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-17 16:12:02,152] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:170)
[2021-04-17 16:12:02,155] INFO [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1205)
[2021-04-17 16:12:02,156] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-17 16:12:02,156] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-17 16:12:02,156] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-17 16:12:02,157] INFO App info kafka.producer for producer-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-17 16:12:02,157] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-17 16:12:02,157] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-17 16:12:02,157] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-17 16:12:02,158] INFO App info kafka.consumer for consumer-connect-cluster-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-17 16:12:02,158] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:196)
[2021-04-17 16:12:02,158] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:285)
[2021-04-17 16:12:02,158] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:170)
[2021-04-17 16:12:02,158] INFO [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1205)
[2021-04-17 16:12:02,159] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-17 16:12:02,159] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-17 16:12:02,159] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-17 16:12:02,159] INFO App info kafka.producer for producer-3 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-17 16:12:02,161] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-17 16:12:02,161] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-17 16:12:02,161] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-17 16:12:02,162] INFO App info kafka.consumer for consumer-connect-cluster-3 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-17 16:12:02,162] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:196)
[2021-04-17 16:12:02,162] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:287)
[2021-04-17 16:12:02,162] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:209)
[2021-04-17 16:12:02,163] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:134)
[2021-04-17 16:12:02,163] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:170)
[2021-04-17 16:12:02,163] INFO [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1205)
[2021-04-17 16:12:02,164] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-17 16:12:02,164] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-17 16:12:02,164] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-17 16:12:02,165] INFO App info kafka.producer for producer-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-17 16:12:02,165] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-17 16:12:02,165] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-17 16:12:02,165] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-17 16:12:02,165] INFO App info kafka.consumer for consumer-connect-cluster-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-17 16:12:02,165] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:196)
[2021-04-17 16:12:02,166] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:136)
[2021-04-17 16:12:02,166] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-17 16:12:02,166] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-17 16:12:02,166] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-17 16:12:02,166] INFO App info kafka.connect for 192.168.0.20:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-17 16:12:02,166] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:230)
[2021-04-17 16:12:02,168] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:300)
[2021-04-17 16:12:02,169] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:702)
[2021-04-17 16:12:02,169] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)

[2021-04-19 11:02:31,491] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../logs, -Dlog4j.configuration=file:bin/../etc/kafka/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 15.0.2, 15.0.2+7-27
	jvm.classpath = /Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/connect-transforms-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jakarta.xml.bind-api-2.3.2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/zstd-jni-1.4.5-6.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jackson-jaxrs-base-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jackson-core-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/connect-api-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/zookeeper-3.5.8.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/rocksdbjni-5.18.4.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jopt-simple-5.0.4.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/kafka-log4j-appender-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jetty-io-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/connect-runtime-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/mysql-connector-java-8.0.23.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/reflections-0.9.12.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/slf4j-log4j12-1.7.30.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/kafka_2.13-6.1.0-ccs-test-sources.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/netty-codec-4.1.51.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/connect-mirror-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jersey-common-2.31.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jetty-server-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/connect-mirror-client-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jetty-util-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jackson-dataformat-csv-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/argparse4j-0.7.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/activation-1.1.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jetty-servlets-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/kafka-clients-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/scala-logging_2.13-3.9.2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/slf4j-api-1.7.30.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/javassist-3.25.0-GA.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/scala-reflect-2.13.3.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jersey-media-jaxb-2.31.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/maven-artifact-3.6.3.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/kafka-streams-test-utils-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/confluent-log4j-1.2.17-cp2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/scala-library-2.13.3.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jackson-jaxrs-json-provider-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jetty-continuation-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/javax.servlet-api-3.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/hk2-locator-2.6.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/scala-collection-compat_2.13-2.2.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jackson-module-paranamer-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/plexus-utils-3.2.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jersey-server-2.31.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/aopalliance-repackaged-2.6.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/scala-java8-compat_2.13-0.9.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/zookeeper-jute-3.5.8.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/netty-transport-4.1.51.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jackson-module-scala_2.13-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/kafka-streams-examples-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/commons-cli-1.4.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/paranamer-2.8.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/kafka-tools-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/netty-common-4.1.51.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/kafka-streams-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jaxb-api-2.3.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jersey-container-servlet-2.31.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/metrics-core-2.2.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jetty-client-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/kafka-streams-scala_2.13-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jakarta.activation-api-1.2.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/lz4-java-1.7.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jetty-http-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/osgi-resource-locator-1.0.3.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jackson-datatype-jdk8-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jersey-container-servlet-core-2.31.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jakarta.inject-2.6.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/audience-annotations-0.5.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/hk2-utils-2.6.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/javax.ws.rs-api-2.1.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/netty-resolver-4.1.51.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jersey-hk2-2.31.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/hk2-api-2.6.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/netty-handler-4.1.51.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jackson-databind-2.10.5.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/connect-basic-auth-extension-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/netty-transport-native-epoll-4.1.51.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jetty-security-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jakarta.annotation-api-1.3.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/snappy-java-1.1.7.7.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/netty-transport-native-unix-common-4.1.51.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/kafka_2.13-6.1.0-ccs-sources.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jackson-annotations-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/connect-json-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jetty-servlet-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/mariadb-java-client-2.7.2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/kafka_2.13-6.1.0-ccs-javadoc.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/connect-file-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/kafka_2.13-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jersey-client-2.31.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/kafka-raft-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/netty-buffer-4.1.51.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/kafka.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/kafka_2.13-6.1.0-ccs-test.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/javassist-3.26.0-GA.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jakarta.validation-api-2.0.2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/jackson-module-jaxb-annotations-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka/commons-lang3-3.8.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/confluent-common/common-config-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/confluent-common/common-metrics-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/confluent-common/slf4j-api-1.7.30.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/confluent-common/build-tools-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/confluent-common/common-utils-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kafka-protobuf-provider-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kafka-streams-avro-serde-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/commons-logging-1.2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/jackson-core-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kotlinx-coroutines-core-1.1.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kotlin-stdlib-1.4.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/rocksdbjni-5.18.4.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/gson-2.8.6.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kotlin-reflect-1.3.50.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kotlin-scripting-common-1.3.50.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/jersey-common-2.31.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/protobuf-java-3.11.4.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/joda-time-2.9.9.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/json-20190722.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kafka-schema-registry-client-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/slf4j-api-1.7.30.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kafka-json-schema-provider-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/wire-runtime-3.2.2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/animal-sniffer-annotations-1.18.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/wire-schema-3.2.2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kafka-connect-protobuf-converter-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/org.everit.json.schema-1.12.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/scala-library-2.13.3.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kafka-connect-json-schema-converter-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/protobuf-java-util-3.11.4.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kafka-connect-avro-data-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/jakarta.ws.rs-api-2.1.6.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kafka-json-schema-serializer-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/commons-validator-1.6.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/failureaccess-1.0.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/okio-2.5.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/annotations-13.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/jackson-datatype-guava-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/error_prone_annotations-2.3.4.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kafka-streams-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kafka-protobuf-serializer-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kafka-schema-serializer-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/swagger-annotations-1.6.2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/avro-1.9.2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/handy-uri-templates-2.1.8.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/osgi-resource-locator-1.0.3.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/validation-api-2.0.1.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/jackson-datatype-jdk8-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kafka-connect-avro-converter-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/jakarta.inject-2.6.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/checker-qual-2.8.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/jackson-module-parameter-names-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kafka-avro-serializer-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/commons-collections-3.2.2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kafka-streams-protobuf-serde-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/commons-compress-1.19.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/jackson-databind-2.10.5.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kafka-streams-json-schema-serde-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kotlin-scripting-jvm-1.3.50.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/jakarta.annotation-api-1.3.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/j2objc-annotations-1.3.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/classgraph-4.8.21.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kotlin-stdlib-jdk7-1.3.71.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kafka-json-serializer-6.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/jackson-annotations-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kotlin-script-runtime-1.3.50.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/re2j-1.3.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kotlin-scripting-compiler-embeddable-1.3.50.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kotlin-stdlib-common-1.3.71.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kotlin-stdlib-jdk8-1.3.71.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/jsr305-3.0.2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/jackson-datatype-joda-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/mbknor-jackson-jsonschema_2.13-1.0.39.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/kotlin-scripting-compiler-impl-embeddable-1.3.50.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/jackson-datatype-jsr310-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/guava-28.1-jre.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/share/java/kafka-serde-tools/commons-digester-1.8.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/connect-transforms-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/zstd-jni-1.4.5-6.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jackson-jaxrs-base-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jackson-core-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/connect-api-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/zookeeper-3.5.8.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/rocksdbjni-5.18.4.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/kafka-log4j-appender-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jetty-io-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/connect-runtime-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/mysql-connector-java-8.0.23.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/reflections-0.9.12.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/slf4j-log4j12-1.7.30.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/kafka_2.13-6.1.0-ccs-test-sources.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/netty-codec-4.1.51.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/connect-mirror-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jersey-common-2.31.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jetty-server-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/connect-mirror-client-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jetty-util-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jackson-dataformat-csv-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/argparse4j-0.7.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/activation-1.1.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jetty-servlets-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/kafka-clients-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/scala-logging_2.13-3.9.2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/slf4j-api-1.7.30.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/javassist-3.25.0-GA.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/scala-reflect-2.13.3.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jersey-media-jaxb-2.31.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/maven-artifact-3.6.3.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/kafka-streams-test-utils-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/confluent-log4j-1.2.17-cp2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/scala-library-2.13.3.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jetty-continuation-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/scala-collection-compat_2.13-2.2.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jackson-module-paranamer-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/plexus-utils-3.2.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jersey-server-2.31.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/scala-java8-compat_2.13-0.9.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/zookeeper-jute-3.5.8.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/netty-transport-4.1.51.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jackson-module-scala_2.13-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/kafka-streams-examples-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/commons-cli-1.4.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/paranamer-2.8.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/kafka-tools-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/netty-common-4.1.51.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/kafka-streams-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jersey-container-servlet-2.31.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/metrics-core-2.2.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jetty-client-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/kafka-streams-scala_2.13-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jakarta.activation-api-1.2.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/lz4-java-1.7.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jetty-http-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jackson-datatype-jdk8-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jersey-container-servlet-core-2.31.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/netty-resolver-4.1.51.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jersey-hk2-2.31.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/hk2-api-2.6.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/netty-handler-4.1.51.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jackson-databind-2.10.5.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/connect-basic-auth-extension-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/netty-transport-native-epoll-4.1.51.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jetty-security-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/snappy-java-1.1.7.7.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.51.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/kafka_2.13-6.1.0-ccs-sources.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jackson-annotations-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/connect-json-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jetty-servlet-9.4.33.v20201020.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/mariadb-java-client-2.7.2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/kafka_2.13-6.1.0-ccs-javadoc.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/connect-file-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/kafka_2.13-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jersey-client-2.31.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/kafka-raft-6.1.0-ccs.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/netty-buffer-4.1.51.Final.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/kafka.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/kafka_2.13-6.1.0-ccs-test.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/javassist-3.26.0-GA.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.10.5.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/Users/etlaou/Downloads/Kafka/confluent-6.1.0/bin/../share/java/confluent-telemetry/*
	os.spec = Mac OS X, x86_64, 10.16
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2021-04-19 11:02:31,505] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectDistributed:90)
[2021-04-19 11:02:31,537] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/osdt_cert-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:31,669] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/osdt_cert-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:31,672] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:31,672] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:31,673] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:31,701] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/xmlparserv2-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:31,906] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/xmlparserv2-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:31,908] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/kafka-connect-jdbc-10.1.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:31,953] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/kafka-connect-jdbc-10.1.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:31,953] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:31,953] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:31,954] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/mysql-connector-java-8.0.23.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:32,099] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/mysql-connector-java-8.0.23.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:32,109] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/ons-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:32,126] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/ons-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:32,127] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/slf4j-api-1.7.30.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:32,134] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/slf4j-api-1.7.30.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:32,135] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/oraclepki-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:32,172] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/oraclepki-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:32,175] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/simplefan-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:32,183] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/simplefan-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:32,184] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/xdb-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:32,204] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/xdb-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:32,205] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/jtds-1.3.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:32,233] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/jtds-1.3.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:32,236] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/mariadb-java-client-2.7.2-sources.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:32,240] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/mariadb-java-client-2.7.2-sources.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:32,242] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/ucp-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:32,325] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/ucp-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:32,327] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/postgresql-42.2.10.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:32,377] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/postgresql-42.2.10.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:32,383] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/common-utils-6.0.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:32,394] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/common-utils-6.0.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:32,395] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/ojdbc8-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:32,644] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/ojdbc8-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:32,731] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/osdt_core-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:32,772] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/osdt_core-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:32,773] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/mariadb-java-client-2.7.2.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:32,814] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/mariadb-java-client-2.7.2.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:32,816] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/sqlite-jdbc-3.25.2.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:32,829] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/sqlite-jdbc-3.25.2.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:32,832] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/orai18n-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:32,840] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/orai18n-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:32,841] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/mssql-jdbc-8.4.1.jre8.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:33,088] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/mssql-jdbc-8.4.1.jre8.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:33,131] INFO Loading plugin from: /Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/mariadb-java-client-2.7.2 2.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-04-19 11:02:33,167] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib/mariadb-java-client-2.7.2%202.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:35,028] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@73d16e93 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-04-19 11:02:35,030] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,030] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,030] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,030] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,030] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,031] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,031] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,031] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,031] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,031] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,031] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,032] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,032] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,032] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,032] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,032] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,032] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,032] INFO Added plugin 'io.confluent.connect.protobuf.ProtobufConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,032] INFO Added plugin 'io.confluent.connect.json.JsonSchemaConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,033] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,033] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,033] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,033] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,033] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,033] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,034] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,034] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,034] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,034] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,034] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,034] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,034] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,034] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,034] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,034] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,035] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,035] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,035] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,035] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,035] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,036] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,036] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,036] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,036] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,036] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,036] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,036] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,036] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,036] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,036] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,036] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-04-19 11:02:35,038] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,039] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,039] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,039] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,039] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,040] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,040] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,040] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,040] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,040] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,041] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,041] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,041] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,041] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,041] INFO Added aliases 'JsonSchemaConverter' and 'JsonSchema' to plugin 'io.confluent.connect.json.JsonSchemaConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,041] INFO Added aliases 'ProtobufConverter' and 'Protobuf' to plugin 'io.confluent.connect.protobuf.ProtobufConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,043] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,043] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,043] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,043] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,043] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,043] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,043] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,044] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,044] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,044] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,044] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,045] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,046] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,046] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,047] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,047] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-04-19 11:02:35,047] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,047] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,048] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-04-19 11:02:35,048] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-04-19 11:02:35,048] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-04-19 11:02:35,048] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-04-19 11:02:35,048] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-04-19 11:02:35,048] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-04-19 11:02:35,048] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-04-19 11:02:35,048] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-04-19 11:02:35,048] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,048] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,048] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-04-19 11:02:35,115] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = None
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.path = [/Users/etlaou/Downloads/Kafka/confluentinc-kafka-connect-jdbc-10.1.0/lib]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:361)
[2021-04-19 11:02:35,119] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2021-04-19 11:02:35,121] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:361)
[2021-04-19 11:02:35,203] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,204] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,204] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,204] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,204] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,204] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,204] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,204] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,204] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,204] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,204] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,204] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,204] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,204] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:35,204] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:35,204] INFO Kafka startTimeMs: 1618797755204 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:35,427] INFO Kafka cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.connect.util.ConnectUtils:65)
[2021-04-19 11:02:35,427] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:02:35,437] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:02:35,437] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:02:35,438] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:02:35,451] INFO Logging initialized @4753ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2021-04-19 11:02:35,481] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2021-04-19 11:02:35,482] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2021-04-19 11:02:35,485] INFO jetty-9.4.33.v20201020; built: 2020-10-20T23:39:24.803Z; git: 1be68755656cef678b79a2ef1c2ebbca99e25420; jvm 15.0.2+7-27 (org.eclipse.jetty.server.Server:375)
[2021-04-19 11:02:35,504] INFO Started http_8083@24934262{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2021-04-19 11:02:35,505] INFO Started @4807ms (org.eclipse.jetty.server.Server:415)
[2021-04-19 11:02:35,527] INFO Advertised URI: http://218.38.137.28:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2021-04-19 11:02:35,527] INFO REST server listening at http://218.38.137.28:8083/, advertising URL http://218.38.137.28:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2021-04-19 11:02:35,528] INFO Advertised URI: http://218.38.137.28:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2021-04-19 11:02:35,528] INFO REST admin endpoints at http://218.38.137.28:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:220)
[2021-04-19 11:02:35,528] INFO Advertised URI: http://218.38.137.28:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2021-04-19 11:02:35,529] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2021-04-19 11:02:35,530] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:361)
[2021-04-19 11:02:35,560] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,560] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,560] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,560] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,560] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,560] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,560] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,561] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,561] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,561] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,561] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,561] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,561] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,562] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:35,562] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:35,563] INFO Kafka startTimeMs: 1618797755561 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:35,593] INFO Kafka cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.connect.util.ConnectUtils:65)
[2021-04-19 11:02:35,595] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:02:35,602] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:02:35,602] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:02:35,603] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:02:35,608] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2021-04-19 11:02:35,611] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2021-04-19 11:02:35,614] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:361)
[2021-04-19 11:02:35,641] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,641] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,641] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,641] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,642] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,642] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,642] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,642] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,642] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,642] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,642] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,642] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,642] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,642] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:35,642] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:35,642] INFO Kafka startTimeMs: 1618797755642 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:35,661] INFO Kafka cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.connect.util.ConnectUtils:65)
[2021-04-19 11:02:35,662] INFO App info kafka.admin.client for adminclient-3 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:02:35,663] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:02:35,663] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:02:35,663] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:02:35,667] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:35,667] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:35,667] INFO Kafka startTimeMs: 1618797755667 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:35,749] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:02:35,751] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:02:35,751] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2021-04-19 11:02:35,751] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:361)
[2021-04-19 11:02:35,758] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,758] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,758] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,758] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,758] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,758] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,758] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,758] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,758] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,758] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,758] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,758] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,758] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,759] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:35,759] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:35,759] INFO Kafka startTimeMs: 1618797755758 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:35,778] INFO Kafka cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.connect.util.ConnectUtils:65)
[2021-04-19 11:02:35,779] INFO App info kafka.admin.client for adminclient-4 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:02:35,780] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:02:35,780] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:02:35,780] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:02:35,829] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2021-04-19 11:02:35,840] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:361)
[2021-04-19 11:02:35,868] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,868] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,868] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,868] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,868] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,868] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,868] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,868] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,869] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,869] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,869] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,869] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,869] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,869] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:35,869] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:35,869] INFO Kafka startTimeMs: 1618797755869 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:35,891] INFO Kafka cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.connect.util.ConnectUtils:65)
[2021-04-19 11:02:35,893] INFO App info kafka.admin.client for adminclient-5 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:02:35,900] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:02:35,900] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:02:35,901] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:02:35,903] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2021-04-19 11:02:35,905] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:361)
[2021-04-19 11:02:35,911] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,911] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,911] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,911] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,911] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,911] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,911] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,911] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,912] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,912] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,912] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,912] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,912] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,912] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:35,912] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:35,912] INFO Kafka startTimeMs: 1618797755912 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:35,925] INFO Kafka cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.connect.util.ConnectUtils:65)
[2021-04-19 11:02:35,929] INFO App info kafka.admin.client for adminclient-6 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:02:35,931] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:02:35,931] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:02:35,931] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:02:35,939] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2021-04-19 11:02:35,939] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:361)
[2021-04-19 11:02:35,942] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,942] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,942] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,943] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,943] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,943] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,943] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,943] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,943] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,943] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,943] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,943] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,943] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,943] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:35,943] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:35,943] INFO Kafka startTimeMs: 1618797755943 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:35,956] INFO Kafka cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.connect.util.ConnectUtils:65)
[2021-04-19 11:02:35,958] INFO App info kafka.admin.client for adminclient-7 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:02:35,959] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:02:35,959] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:02:35,960] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:02:35,988] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:35,989] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:35,989] INFO Kafka startTimeMs: 1618797755987 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:35,991] INFO Kafka Connect distributed worker initialization took 4486ms (org.apache.kafka.connect.cli.ConnectDistributed:128)
[2021-04-19 11:02:35,991] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2021-04-19 11:02:35,992] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:224)
[2021-04-19 11:02:35,993] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:287)
[2021-04-19 11:02:35,993] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:195)
[2021-04-19 11:02:35,993] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:127)
[2021-04-19 11:02:35,993] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:128)
[2021-04-19 11:02:35,995] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:361)
[2021-04-19 11:02:35,998] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,998] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:35,999] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,000] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,008] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,008] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,008] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,008] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,008] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,009] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,009] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,009] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,010] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,010] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,010] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,010] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:36,010] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:36,010] INFO Kafka startTimeMs: 1618797756010 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:36,055] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:241)
[2021-04-19 11:02:36,089] INFO App info kafka.admin.client for adminclient-8 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:02:36,093] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:02:36,094] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:02:36,094] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:02:36,108] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:361)
[2021-04-19 11:02:36,149] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,151] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,151] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,151] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,152] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,152] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,153] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,154] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,154] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,155] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,155] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,155] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,156] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,156] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,157] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,158] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:36,158] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:36,158] INFO Kafka startTimeMs: 1618797756157 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:36,166] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-connect-cluster-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-04-19 11:02:36,189] INFO [Producer clientId=producer-1] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:02:36,193] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2021-04-19 11:02:36,194] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2021-04-19 11:02:36,195] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2021-04-19 11:02:36,208] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,208] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,209] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,214] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,215] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,215] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,215] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,216] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,216] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,216] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,216] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,216] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,217] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,217] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,217] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:36,217] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:36,217] INFO Kafka startTimeMs: 1618797756217 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:36,226] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:02:36,239] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Subscribed to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.KafkaConsumer:1116)
[2021-04-19 11:02:36,241] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,243] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,244] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,244] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,244] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,244] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,244] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,244] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,244] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,244] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,244] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,244] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,244] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,244] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,244] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,244] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,245] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,245] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,245] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,245] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,245] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,246] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,246] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,246] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,246] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,290] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,296] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,304] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,305] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,305] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,306] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,306] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,306] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,307] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,307] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,308] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,308] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,308] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,308] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,309] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,311] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,313] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,313] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,313] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,313] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,313] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,313] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,314] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,314] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,314] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,413] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:164)
[2021-04-19 11:02:36,413] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:166)
[2021-04-19 11:02:36,414] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:129)
[2021-04-19 11:02:36,416] INFO Worker started (org.apache.kafka.connect.runtime.Worker:202)
[2021-04-19 11:02:36,416] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:128)
[2021-04-19 11:02:36,418] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:361)
[2021-04-19 11:02:36,422] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,423] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,423] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,423] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,423] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,423] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,424] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,424] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,424] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,424] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,424] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,424] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,424] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,425] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,425] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,425] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:36,425] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:36,425] INFO Kafka startTimeMs: 1618797756425 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:36,456] INFO App info kafka.admin.client for adminclient-9 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:02:36,457] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:02:36,457] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:02:36,457] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:02:36,458] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:361)
[2021-04-19 11:02:36,463] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,464] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,464] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,464] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,464] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,464] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,464] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,464] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,465] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,465] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,465] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,466] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,466] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,466] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,466] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,467] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:36,467] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:36,468] INFO Kafka startTimeMs: 1618797756467 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:36,472] INFO [Producer clientId=producer-2] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:02:36,473] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-connect-cluster-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-04-19 11:02:36,478] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,478] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,478] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,478] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,478] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,479] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,479] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,479] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,479] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,479] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,480] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,480] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,480] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,480] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,480] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:36,481] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:36,481] INFO Kafka startTimeMs: 1618797756480 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:36,493] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:02:36,493] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Subscribed to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.KafkaConsumer:1116)
[2021-04-19 11:02:36,494] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,494] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,494] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,494] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,494] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,512] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,514] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,514] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,514] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,514] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,558] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:164)
[2021-04-19 11:02:36,558] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:166)
[2021-04-19 11:02:36,559] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:265)
[2021-04-19 11:02:36,559] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:128)
[2021-04-19 11:02:36,560] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:361)
[2021-04-19 11:02:36,570] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,570] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,570] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,571] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,571] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,571] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,571] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,572] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,572] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,573] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,573] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,573] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,573] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,574] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,574] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-04-19 11:02:36,574] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:36,574] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:36,574] INFO Kafka startTimeMs: 1618797756574 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:36,608] INFO App info kafka.admin.client for adminclient-10 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:02:36,609] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:02:36,609] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:02:36,609] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:02:36,612] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:361)
[2021-04-19 11:02:36,619] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,619] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,620] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,620] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,621] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,622] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,623] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,623] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,623] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,623] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,623] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,625] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,627] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,628] INFO [Producer clientId=producer-3] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:02:36,628] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,629] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:36,630] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:36,630] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:36,631] INFO Kafka startTimeMs: 1618797756630 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:36,632] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-connect-cluster-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-04-19 11:02:36,649] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,650] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,650] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,651] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,651] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,651] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,652] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,652] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,652] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,652] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,652] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,652] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,652] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,653] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:02:36,653] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:36,653] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:36,653] INFO Kafka startTimeMs: 1618797756653 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:36,664] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:02:36,665] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Subscribed to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1116)
[2021-04-19 11:02:36,666] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:618)
[2021-04-19 11:02:36,680] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:02:36,690] INFO Successfully processed removal of connector 'signin-connect' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:578)
[2021-04-19 11:02:36,691] INFO Successfully processed removal of connector 'signup-connect' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:578)
[2021-04-19 11:02:36,693] INFO Successfully processed removal of connector 'signup-connect' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:578)
[2021-04-19 11:02:36,695] INFO Successfully processed removal of connector 'signup-connect' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:578)
[2021-04-19 11:02:36,695] INFO Successfully processed removal of connector 'signin-connect' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:578)
[2021-04-19 11:02:36,700] INFO Successfully processed removal of connector 'signup-connect' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:578)
[2021-04-19 11:02:36,701] INFO Successfully processed removal of connector 'signin-connect' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:578)
[2021-04-19 11:02:36,706] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:164)
[2021-04-19 11:02:36,706] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:166)
[2021-04-19 11:02:36,707] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:280)
[2021-04-19 11:02:36,707] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:291)
[2021-04-19 11:02:36,723] INFO [Worker clientId=connect-1, groupId=connect-cluster] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:02:36,725] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-04-19 11:02:36,727] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:02:36,729] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:02:36,762] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:02:36,791] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=39, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:02:36,872] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=39, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:02:36,874] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 39 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=44, connectorIds=[source-connect, signup-connect], taskIds=[source-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:02:36,876] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1095)
[2021-04-19 11:02:36,877] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset -1 is behind group assignment 44, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1158)
[2021-04-19 11:02:36,950] INFO Started o.e.j.s.ServletContextHandler@32e652b6{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:916)
[2021-04-19 11:02:36,950] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:319)
[2021-04-19 11:02:36,950] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2021-04-19 11:02:37,194] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 44 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1162)
[2021-04-19 11:02:37,196] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 44 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:02:37,201] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task source-connect-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1258)
[2021-04-19 11:02:37,201] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task signup-connect-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1258)
[2021-04-19 11:02:37,204] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector signup-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1299)
[2021-04-19 11:02:37,205] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector source-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1299)
[2021-04-19 11:02:37,210] INFO Creating task source-connect-0 (org.apache.kafka.connect.runtime.Worker:509)
[2021-04-19 11:02:37,210] INFO Creating task signup-connect-0 (org.apache.kafka.connect.runtime.Worker:509)
[2021-04-19 11:02:37,211] INFO Creating connector source-connect of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:274)
[2021-04-19 11:02:37,211] INFO Creating connector signup-connect of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:274)
[2021-04-19 11:02:37,232] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-04-19 11:02:37,233] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signup-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-19 11:02:37,233] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-19 11:02:37,232] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signup-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-04-19 11:02:37,234] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:02:37,234] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signup-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:02:37,234] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:02:37,234] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signup-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:02:37,246] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-04-19 11:02:37,246] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-04-19 11:02:37,249] INFO Instantiated task source-connect-0 with version 10.1.0 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-04-19 11:02:37,249] INFO Instantiated task signup-connect-0 with version 10.1.0 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-04-19 11:02:37,250] INFO Instantiated connector source-connect with version 10.1.0 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:284)
[2021-04-19 11:02:37,251] INFO Instantiated connector signup-connect with version 10.1.0 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:284)
[2021-04-19 11:02:37,251] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:02:37,251] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:02:37,252] INFO Finished creating connector signup-connect (org.apache.kafka.connect.runtime.Worker:310)
[2021-04-19 11:02:37,252] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task source-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:537)
[2021-04-19 11:02:37,252] INFO Finished creating connector source-connect (org.apache.kafka.connect.runtime.Worker:310)
[2021-04-19 11:02:37,252] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task signup-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:537)
[2021-04-19 11:02:37,253] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2021-04-19 11:02:37,252] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:02:37,253] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2021-04-19 11:02:37,253] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:02:37,254] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task source-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:543)
[2021-04-19 11:02:37,254] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task signup-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:543)
[2021-04-19 11:02:37,255] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task source-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-04-19 11:02:37,255] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task signup-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-04-19 11:02:37,264] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signup-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-19 11:02:37,264] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-19 11:02:37,266] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signup-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:02:37,267] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:02:37,269] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:606)
[2021-04-19 11:02:37,269] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:606)
[2021-04-19 11:02:37,276] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-signup-connect-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:361)
[2021-04-19 11:02:37,276] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-source-connect-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:361)
[2021-04-19 11:02:37,285] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [users]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.initial = null
	topic.prefix = potato_
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:361)
[2021-04-19 11:02:37,286] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [users]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.initial = null
	topic.prefix = market_
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:361)
[2021-04-19 11:02:37,293] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:02:37,293] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:02:37,296] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:37,297] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:37,298] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:37,301] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:02:37,301] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:37,301] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:37,302] INFO Kafka startTimeMs: 1618797757301 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:37,304] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:02:37,305] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:02:37,305] INFO Kafka startTimeMs: 1618797757301 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:02:37,341] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:02:37,366] INFO [Producer clientId=connector-producer-source-connect-0] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:02:37,366] INFO [Producer clientId=connector-producer-signup-connect-0] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:02:37,406] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:85)
[2021-04-19 11:02:37,406] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:85)
[2021-04-19 11:02:37,417] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [users]
	tables = [`potato`.`users`]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.initial = null
	topic.prefix = potato_
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:361)
[2021-04-19 11:02:37,417] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [users]
	tables = [`potato`.`users`]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.initial = null
	topic.prefix = market_
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:361)
[2021-04-19 11:02:37,418] INFO Using JDBC dialect MySql (io.confluent.connect.jdbc.source.JdbcSourceTask:102)
[2021-04-19 11:02:37,420] INFO Using JDBC dialect MySql (io.confluent.connect.jdbc.source.JdbcSourceTask:102)
[2021-04-19 11:02:37,474] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1578)
[2021-04-19 11:02:37,562] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2021-04-19 11:02:37,562] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2021-04-19 11:02:37,569] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signup-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-19 11:02:37,570] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = signup-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:02:37,635] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-19 11:02:37,636] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:02:37,980] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:02:37,980] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:02:38,079] INFO Found offset {{table=users}=null, {protocol=1, table=potato.users}={incrementing=2}} for partition {protocol=1, table=potato.users} (io.confluent.connect.jdbc.source.JdbcSourceTask:193)
[2021-04-19 11:02:38,080] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:261)
[2021-04-19 11:02:38,080] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:261)
[2021-04-19 11:02:38,080] INFO WorkerSourceTask{id=source-connect-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:233)
[2021-04-19 11:02:38,080] INFO WorkerSourceTask{id=signup-connect-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:233)
[2021-04-19 11:02:38,083] INFO Begin using SQL query: SELECT * FROM `potato`.`users` WHERE `potato`.`users`.`id` > ? ORDER BY `potato`.`users`.`id` ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2021-04-19 11:02:38,083] INFO Begin using SQL query: SELECT * FROM `potato`.`users` WHERE `potato`.`users`.`id` > ? ORDER BY `potato`.`users`.`id` ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2021-04-19 11:02:38,248] WARN [Producer clientId=connector-producer-signup-connect-0] Error while fetching metadata with correlation id 3 : {potato_users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1117)
[2021-04-19 11:02:38,360] WARN [Producer clientId=connector-producer-signup-connect-0] Error while fetching metadata with correlation id 4 : {potato_users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1117)
[2021-04-19 11:02:47,321] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:02:47,324] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:02:47,393] INFO WorkerSourceTask{id=source-connect-0} Finished commitOffsets successfully in 69 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:574)
[2021-04-19 11:02:47,393] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:02:47,393] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:02:47,398] INFO WorkerSourceTask{id=signup-connect-0} Finished commitOffsets successfully in 5 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:574)
[2021-04-19 11:02:57,400] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:02:57,405] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:02:57,407] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:02:57,407] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:03:07,419] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:03:07,431] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:03:07,432] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:03:07,433] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:03:17,442] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:03:17,452] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:03:17,453] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:03:17,453] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:03:27,455] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:03:27,456] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:03:27,457] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:03:27,457] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:03:37,460] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:03:37,461] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:03:37,462] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:03:37,462] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:03:47,465] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:03:47,467] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:03:47,468] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:03:47,468] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:03:57,471] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:03:57,472] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:03:57,473] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:03:57,473] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:04:07,478] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:04:07,484] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:04:07,485] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:04:07,485] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:04:17,488] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:04:17,492] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:04:17,493] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:04:17,493] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:04:27,498] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:04:27,499] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:04:27,499] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:04:27,500] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:04:37,504] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:04:37,506] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:04:37,506] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:04:37,506] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:04:47,508] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:04:47,509] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:04:47,510] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:04:47,510] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:04:49,261] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:361)
[2021-04-19 11:04:49,286] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector sink-connect config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1534)
[2021-04-19 11:04:49,288] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:04:49,288] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:04:49,294] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=40, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:04:49,305] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=40, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:04:49,308] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 40 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=46, connectorIds=[sink-connect, source-connect, signup-connect], taskIds=[source-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:04:49,309] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 46 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:04:49,311] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector sink-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1299)
[2021-04-19 11:04:49,312] INFO Creating connector sink-connect of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:274)
[2021-04-19 11:04:49,313] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-19 11:04:49,313] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:04:49,319] INFO Instantiated connector sink-connect with version 10.1.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:284)
[2021-04-19 11:04:49,320] INFO Finished creating connector sink-connect (org.apache.kafka.connect.runtime.Worker:310)
[2021-04-19 11:04:49,320] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:04:49,321] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-19 11:04:49,322] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:04:49,323] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2021-04-19 11:04:49,810] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [sink-connect-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1549)
[2021-04-19 11:04:49,813] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling task config update by restarting tasks [] (org.apache.kafka.connect.runtime.distributed.DistributedHerder:647)
[2021-04-19 11:04:49,813] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:04:49,813] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:04:49,817] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=41, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:04:49,822] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=41, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:04:49,823] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 41 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=48, connectorIds=[sink-connect, source-connect, signup-connect], taskIds=[sink-connect-0, source-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:04:49,824] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 48 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:04:49,826] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task sink-connect-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1258)
[2021-04-19 11:04:49,826] INFO Creating task sink-connect-0 (org.apache.kafka.connect.runtime.Worker:509)
[2021-04-19 11:04:49,828] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-04-19 11:04:49,828] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:04:49,830] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-04-19 11:04:49,830] INFO Instantiated task sink-connect-0 with version 10.1.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-04-19 11:04:49,835] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:04:49,835] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:537)
[2021-04-19 11:04:49,838] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:04:49,839] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:543)
[2021-04-19 11:04:49,839] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-04-19 11:04:49,840] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-04-19 11:04:49,841] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-19 11:04:49,841] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:04:49,842] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-connect-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-connect
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-04-19 11:04:49,854] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:04:49,854] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:04:49,854] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:04:49,854] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:04:49,854] INFO Kafka startTimeMs: 1618797889854 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:04:49,858] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:04:49,860] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Subscribed to topic(s): market_users (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-04-19 11:04:49,860] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:48)
[2021-04-19 11:04:49,861] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:361)
[2021-04-19 11:04:49,868] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:04:49,869] INFO WorkerSinkTask{id=sink-connect-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-04-19 11:04:49,890] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:04:49,891] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-04-19 11:04:49,892] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:04:49,901] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:04:49,905] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-sink-connect-0-48f613a4-6b2c-4e00-8c4e-e715330a591c', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:04:49,908] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Finished assignment for group at generation 1: {connector-consumer-sink-connect-0-48f613a4-6b2c-4e00-8c4e-e715330a591c=Assignment(partitions=[market_users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2021-04-19 11:04:49,913] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-sink-connect-0-48f613a4-6b2c-4e00-8c4e-e715330a591c', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:04:49,913] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Notifying assignor about the new Assignment(partitions=[market_users-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-04-19 11:04:49,913] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Adding newly assigned partitions: market_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-04-19 11:04:49,916] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Found no committed offset for partition market_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1354)
[2021-04-19 11:04:49,922] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Resetting offset for partition market_users-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:04:49,943] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:04:49,957] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:04:49,966] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:04:49,971] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:04:49,987] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:04:49,992] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:04:57,515] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:04:57,517] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:04:57,518] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:04:57,518] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:04:59,863] INFO WorkerSinkTask{id=sink-connect-0} Committing offsets asynchronously using sequence number 1: {market_users-0=OffsetAndMetadata{offset=4, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:352)
[2021-04-19 11:05:07,524] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:05:07,525] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:05:07,527] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:05:07,527] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:05:17,532] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:05:17,536] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:05:17,537] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:05:17,537] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:05:27,542] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:05:27,543] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:05:27,543] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:05:27,543] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:05:37,549] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:05:37,552] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:05:37,552] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:05:37,553] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:05:47,558] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:05:47,560] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:05:47,560] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:05:47,561] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:05:57,565] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:05:57,565] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:05:57,566] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:05:57,566] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:06:07,571] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:06:07,572] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:06:07,572] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:06:07,573] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:06:10,610] WARN Write of 4 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:06:10,614] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:06:10,616] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:06:10,616] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:06:13,622] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:06:13,636] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:06:13,643] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:06:13,669] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:06:13,698] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:06:13,705] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:06:13,708] WARN Write of 4 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:06:13,708] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:06:13,710] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:06:13,710] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:06:16,714] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:06:16,737] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:06:16,745] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:06:16,754] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:06:16,791] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:06:16,796] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:06:16,800] WARN Write of 4 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:06:16,801] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:06:16,801] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:06:16,802] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:06:17,578] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:06:17,578] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:06:17,579] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:06:17,579] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:06:19,809] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:06:19,821] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:06:19,835] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:06:19,845] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:06:19,868] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:06:19,872] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:06:19,876] WARN Write of 4 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:06:19,877] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:06:19,878] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:06:19,878] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:06:19,903] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:06:19,908] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:06:19,912] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:06:19,917] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:06:19,930] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:06:19,935] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:06:19,937] WARN Write of 4 records failed, remainingRetries=6 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:06:19,938] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:06:19,938] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:06:19,938] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:06:22,940] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:06:22,950] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:06:22,969] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:06:22,986] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:06:22,998] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:06:23,015] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:06:23,022] WARN Write of 4 records failed, remainingRetries=5 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:06:23,023] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:06:23,025] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:06:23,025] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:06:26,039] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:06:26,048] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:06:26,058] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:06:26,069] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:06:26,083] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:06:26,089] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:06:26,093] WARN Write of 4 records failed, remainingRetries=4 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:06:26,094] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:06:26,095] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:06:26,095] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:06:27,584] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:06:27,588] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:06:27,589] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:06:27,589] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:06:29,098] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:06:29,110] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:06:29,116] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:06:29,120] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:06:29,131] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:06:29,135] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:06:29,141] WARN Write of 4 records failed, remainingRetries=3 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:06:29,142] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:06:29,142] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:06:29,143] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:06:29,944] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:06:29,959] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:06:29,972] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:06:29,977] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:06:29,992] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:06:29,996] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:06:30,000] WARN Write of 4 records failed, remainingRetries=2 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:06:30,001] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:06:30,002] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:06:30,002] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:06:33,006] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:06:33,018] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:06:33,029] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:06:33,050] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:06:33,061] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:06:33,063] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:06:33,072] WARN Write of 4 records failed, remainingRetries=1 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:06:33,072] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:06:33,073] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:06:33,073] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:06:36,077] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:06:36,089] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:06:36,101] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:06:36,108] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:06:36,125] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:06:36,130] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:06:36,135] WARN Write of 4 records failed, remainingRetries=0 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:06:36,137] ERROR Failing task after exhausting retries; encountered 2 exceptions on last write attempt. For complete details on each exception, please enable DEBUG logging. (io.confluent.connect.jdbc.sink.JdbcSinkTask:113)
[2021-04-19 11:06:36,137] ERROR WorkerSinkTask{id=sink-connect-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'
 (org.apache.kafka.connect.runtime.WorkerSinkTask:612)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:122)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:06:36,138] ERROR WorkerSinkTask{id=sink-connect-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:614)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:122)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	... 10 more
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '4' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '4' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:06:36,138] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:161)
[2021-04-19 11:06:36,139] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:06:36,139] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Revoke previously assigned partitions market_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2021-04-19 11:06:36,140] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Member connector-consumer-sink-connect-0-48f613a4-6b2c-4e00-8c4e-e715330a591c sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-04-19 11:06:36,151] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:06:36,151] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:06:36,151] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:06:36,156] INFO App info kafka.consumer for connector-consumer-sink-connect-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:06:37,593] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:06:37,596] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:06:37,596] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:06:37,597] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:06:47,600] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:06:47,603] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:06:47,604] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:06:47,605] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:06:57,608] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:06:57,609] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:06:57,636] INFO WorkerSourceTask{id=source-connect-0} Finished commitOffsets successfully in 28 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:574)
[2021-04-19 11:06:57,637] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:06:57,637] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:06:57,646] INFO WorkerSourceTask{id=signup-connect-0} Finished commitOffsets successfully in 8 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:574)
[2021-04-19 11:07:07,642] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:07:07,645] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:07:07,646] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:07:07,646] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:07:17,650] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:07:17,651] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:07:17,651] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:07:17,652] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:07:27,656] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:07:27,657] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:07:27,657] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:07:27,657] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:07:37,663] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:07:37,665] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:07:37,666] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:07:37,666] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:07:47,669] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:07:47,670] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:07:47,670] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:07:47,670] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:07:57,673] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:07:57,674] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:07:57,674] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:07:57,674] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:08:07,679] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:08:07,681] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:08:07,681] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:08:07,682] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:08:17,687] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:08:17,699] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:08:17,700] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:08:17,700] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:08:27,701] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:08:27,702] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:08:27,703] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:08:27,704] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:08:37,706] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:08:37,707] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:08:37,708] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:08:37,708] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:08:47,712] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:08:47,713] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:08:47,714] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:08:47,714] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:08:57,718] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:08:57,718] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:08:57,719] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:08:57,719] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:09:07,724] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:09:07,725] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:09:07,728] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:09:07,728] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:09:17,733] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:09:17,735] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:09:17,737] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:09:17,737] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:09:27,738] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:09:27,739] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:09:27,739] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:09:27,740] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:09:37,742] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:09:37,743] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:09:37,744] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:09:37,744] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:09:47,751] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:09:47,753] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:09:47,753] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:09:47,754] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:09:57,758] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:09:57,759] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:09:57,759] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:09:57,759] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:10:07,760] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:10:07,763] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:10:07,763] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:10:07,764] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:10:17,757] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:10:17,758] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:10:17,758] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:10:17,758] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:10:27,755] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:10:27,755] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:10:27,755] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:10:27,756] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:10:37,758] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:10:37,758] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:10:37,759] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:10:37,759] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:10:47,763] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:10:47,765] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:10:47,766] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:10:47,767] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:10:57,767] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:10:57,770] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:10:57,771] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:10:57,772] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:11:07,776] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:11:07,780] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:11:07,781] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:11:07,782] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:11:17,790] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:11:17,791] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:11:17,792] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:11:17,793] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:11:27,795] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:11:27,796] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:11:27,797] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:11:27,798] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:11:37,798] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:11:37,800] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:11:37,801] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:11:37,801] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:11:47,804] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:11:47,805] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:11:47,806] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:11:47,806] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:11:57,809] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:11:57,810] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:11:57,811] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:11:57,811] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:12:07,816] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:12:07,818] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:12:07,820] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:12:07,820] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:12:17,824] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:12:17,825] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:12:17,826] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:12:17,826] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:12:27,827] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:12:27,829] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:12:27,830] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:12:27,830] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:12:37,843] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:12:37,855] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:12:37,857] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:12:37,857] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:12:47,862] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:12:47,863] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:12:47,864] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:12:47,865] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:12:57,869] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:12:57,869] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:12:57,875] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:12:57,875] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:13:07,875] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:13:07,878] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:13:07,879] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:13:07,880] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:13:17,885] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:13:17,886] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:13:17,886] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:13:17,887] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:13:27,892] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:13:27,893] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:13:27,895] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:13:27,896] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:13:37,897] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:13:37,899] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:13:37,900] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:13:37,901] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:13:47,901] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:13:47,903] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:13:47,904] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:13:47,905] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:13:57,908] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:13:57,911] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:13:57,912] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:13:57,913] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:14:07,915] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:14:07,918] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:14:07,919] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:14:07,920] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:14:17,923] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:14:17,923] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:14:17,923] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:14:17,923] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:14:27,929] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:14:27,932] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:14:27,933] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:14:27,933] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:14:37,935] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:14:37,937] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:14:37,938] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:14:37,938] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:14:47,941] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:14:47,942] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:14:47,943] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:14:47,944] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:14:57,945] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:14:57,946] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:14:57,946] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:14:57,946] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:15:07,953] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:15:07,960] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:15:07,962] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:15:07,962] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:15:17,966] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:15:17,967] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:15:17,968] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:15:17,968] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:15:27,969] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:15:27,971] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:15:27,972] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:15:27,972] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:15:37,977] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:15:37,978] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:15:37,979] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:15:37,980] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:15:47,982] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:15:47,984] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:15:47,986] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:15:47,986] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:15:57,985] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:15:57,986] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:15:57,986] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:15:57,986] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:16:07,992] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:16:07,993] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:16:07,995] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:16:07,995] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:16:17,996] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:16:17,997] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:16:17,999] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:16:17,999] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:16:28,003] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:16:28,005] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:16:28,006] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:16:28,006] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:16:38,014] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:16:38,017] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:16:38,019] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:16:38,019] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:16:48,023] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:16:48,025] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:16:48,026] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:16:48,026] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:16:58,028] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:16:58,030] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:16:58,031] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:16:58,031] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:17:08,035] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:17:08,037] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:17:08,038] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:17:08,039] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:17:18,044] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:17:18,046] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:17:18,047] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:17:18,047] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:17:28,050] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:17:28,051] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:17:28,052] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:17:28,052] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:17:38,057] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:17:38,058] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:17:38,059] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:17:38,059] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:17:48,064] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:17:48,067] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:17:48,068] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:17:48,069] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:17:58,073] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:17:58,076] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:17:58,077] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:17:58,078] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:18:08,082] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:18:08,085] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:18:08,087] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:18:08,087] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:18:10,131] INFO Successfully processed removal of connector 'sink-connect' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:578)
[2021-04-19 11:18:10,132] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector sink-connect config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1521)
[2021-04-19 11:18:10,133] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling connector-only config update by stopping connector sink-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:593)
[2021-04-19 11:18:10,133] INFO Stopping connector sink-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-19 11:18:10,134] INFO Scheduled shutdown for WorkerConnector{id=sink-connect} (org.apache.kafka.connect.runtime.WorkerConnector:249)
[2021-04-19 11:18:10,146] INFO Completed shutdown for WorkerConnector{id=sink-connect} (org.apache.kafka.connect.runtime.WorkerConnector:269)
[2021-04-19 11:18:10,154] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:18:10,154] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:18:10,165] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=42, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:18:10,192] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=42, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:18:10,197] INFO Stopping connector sink-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-19 11:18:10,197] INFO Stopping task sink-connect-0 (org.apache.kafka.connect.runtime.Worker:836)
[2021-04-19 11:18:10,197] WARN Ignoring stop request for unowned connector sink-connect (org.apache.kafka.connect.runtime.Worker:390)
[2021-04-19 11:18:10,197] WARN Ignoring await stop request for non-present connector sink-connect (org.apache.kafka.connect.runtime.Worker:415)
[2021-04-19 11:18:10,206] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1767)
[2021-04-19 11:18:10,210] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1786)
[2021-04-19 11:18:10,214] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 42 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=50, connectorIds=[source-connect, signup-connect], taskIds=[source-connect-0, signup-connect-0], revokedConnectorIds=[sink-connect], revokedTaskIds=[sink-connect-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:18:10,216] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 50 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:18:10,217] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:18:10,217] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:18:10,217] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:18:10,220] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=43, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:18:10,223] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=43, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:18:10,224] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 43 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=50, connectorIds=[source-connect, signup-connect], taskIds=[source-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:18:10,224] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 50 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:18:10,224] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:18:18,091] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:18:18,092] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:18:18,093] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:18:18,093] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:18:25,771] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:361)
[2021-04-19 11:18:25,786] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector sink-connect config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1534)
[2021-04-19 11:18:25,786] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:18:25,786] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:18:25,789] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=44, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:18:25,794] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=44, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:18:25,795] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 44 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=51, connectorIds=[sink-connect, source-connect, signup-connect], taskIds=[source-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:18:25,796] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 51 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:18:25,799] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector sink-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1299)
[2021-04-19 11:18:25,799] INFO Creating connector sink-connect of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:274)
[2021-04-19 11:18:25,803] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-19 11:18:25,804] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:18:25,807] INFO Instantiated connector sink-connect with version 10.1.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:284)
[2021-04-19 11:18:25,807] INFO Finished creating connector sink-connect (org.apache.kafka.connect.runtime.Worker:310)
[2021-04-19 11:18:25,808] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:18:25,808] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-19 11:18:25,809] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:18:25,809] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2021-04-19 11:18:26,324] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [sink-connect-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1549)
[2021-04-19 11:18:26,324] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling task config update by restarting tasks [] (org.apache.kafka.connect.runtime.distributed.DistributedHerder:647)
[2021-04-19 11:18:26,324] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:18:26,324] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:18:26,327] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=45, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:18:26,334] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=45, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:18:26,335] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 45 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=53, connectorIds=[sink-connect, source-connect, signup-connect], taskIds=[sink-connect-0, source-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:18:26,336] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 53 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:18:26,337] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task sink-connect-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1258)
[2021-04-19 11:18:26,337] INFO Creating task sink-connect-0 (org.apache.kafka.connect.runtime.Worker:509)
[2021-04-19 11:18:26,339] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-04-19 11:18:26,339] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:18:26,340] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-04-19 11:18:26,340] INFO Instantiated task sink-connect-0 with version 10.1.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-04-19 11:18:26,342] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:18:26,342] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:537)
[2021-04-19 11:18:26,342] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:18:26,343] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:543)
[2021-04-19 11:18:26,343] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-04-19 11:18:26,345] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-04-19 11:18:26,345] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-19 11:18:26,346] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:18:26,346] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-connect-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-connect
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-04-19 11:18:26,360] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:18:26,360] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:18:26,361] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:18:26,361] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:18:26,361] INFO Kafka startTimeMs: 1618798706360 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:18:26,363] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:18:26,364] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Subscribed to topic(s): market_users (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-04-19 11:18:26,364] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:48)
[2021-04-19 11:18:26,365] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:361)
[2021-04-19 11:18:26,367] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:18:26,367] INFO WorkerSinkTask{id=sink-connect-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-04-19 11:18:26,396] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:18:26,398] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-04-19 11:18:26,399] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:18:26,408] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:18:26,413] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-sink-connect-0-ca2f7411-f917-4642-8d83-719559fa4443', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:18:26,414] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Finished assignment for group at generation 3: {connector-consumer-sink-connect-0-ca2f7411-f917-4642-8d83-719559fa4443=Assignment(partitions=[market_users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2021-04-19 11:18:26,417] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Successfully synced group in generation Generation{generationId=3, memberId='connector-consumer-sink-connect-0-ca2f7411-f917-4642-8d83-719559fa4443', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:18:26,417] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Notifying assignor about the new Assignment(partitions=[market_users-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-04-19 11:18:26,417] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Adding newly assigned partitions: market_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-04-19 11:18:26,424] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Setting offset for partition market_users-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:820)
[2021-04-19 11:18:26,446] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:18:26,457] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:18:26,460] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:18:26,467] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:18:26,479] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:18:26,483] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:18:26,491] WARN Write of 7 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:18:26,492] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:18:26,494] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:18:26,494] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:18:28,099] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:18:28,103] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:18:28,105] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:18:28,105] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:18:29,501] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:18:29,513] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:18:29,520] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:18:29,527] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:18:29,537] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:18:29,541] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:18:29,552] WARN Write of 7 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:18:29,554] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:18:29,554] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:18:29,554] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:18:32,561] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:18:32,571] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:18:32,579] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:18:32,583] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:18:32,594] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:18:32,598] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:18:32,602] WARN Write of 7 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:18:32,602] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:18:32,603] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:18:32,603] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:18:35,607] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:18:35,615] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:18:35,620] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:18:35,624] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:18:35,636] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:18:35,640] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:18:35,645] WARN Write of 7 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:18:35,645] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:18:35,646] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:18:35,647] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:18:36,374] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:18:36,384] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:18:36,388] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:18:36,393] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:18:36,403] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:18:36,406] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:18:36,420] WARN Write of 7 records failed, remainingRetries=6 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:18:36,421] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:18:36,421] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:18:36,421] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:18:38,110] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:18:38,111] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:18:38,112] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:18:38,113] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:18:39,429] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:18:39,437] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:18:39,443] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:18:39,448] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:18:39,457] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:18:39,460] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:18:39,466] WARN Write of 7 records failed, remainingRetries=5 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:18:39,467] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:18:39,468] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:18:39,468] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:18:42,474] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:18:42,482] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:18:42,491] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:18:42,495] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:18:42,505] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:18:42,508] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:18:42,511] WARN Write of 7 records failed, remainingRetries=4 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:18:42,512] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:18:42,513] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:18:42,513] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:18:45,514] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:18:45,523] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:18:45,527] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:18:45,531] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:18:45,545] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:18:45,551] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:18:45,562] WARN Write of 7 records failed, remainingRetries=3 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:18:45,562] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:18:45,563] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:18:45,563] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:18:46,430] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:18:46,437] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:18:46,442] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:18:46,447] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:18:46,459] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:18:46,464] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:18:46,471] WARN Write of 7 records failed, remainingRetries=2 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:18:46,472] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:18:46,473] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:18:46,473] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:18:48,115] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:18:48,116] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:18:48,117] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:18:48,118] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:18:49,478] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:18:49,485] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:18:49,496] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:18:49,499] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:18:49,507] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:18:49,510] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:18:49,517] WARN Write of 7 records failed, remainingRetries=1 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:18:49,517] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:18:49,518] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:18:49,518] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:18:52,522] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:18:52,530] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:18:52,535] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:18:52,539] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:18:52,549] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:18:52,552] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:18:52,558] WARN Write of 7 records failed, remainingRetries=0 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:18:52,558] ERROR Failing task after exhausting retries; encountered 2 exceptions on last write attempt. For complete details on each exception, please enable DEBUG logging. (io.confluent.connect.jdbc.sink.JdbcSinkTask:113)
[2021-04-19 11:18:52,558] ERROR WorkerSinkTask{id=sink-connect-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
 (org.apache.kafka.connect.runtime.WorkerSinkTask:612)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:122)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:18:52,559] ERROR WorkerSinkTask{id=sink-connect-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:614)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:122)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	... 10 more
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:18:52,559] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:161)
[2021-04-19 11:18:52,559] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:18:52,560] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Revoke previously assigned partitions market_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2021-04-19 11:18:52,560] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Member connector-consumer-sink-connect-0-ca2f7411-f917-4642-8d83-719559fa4443 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-04-19 11:18:52,570] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:18:52,570] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:18:52,570] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:18:52,573] INFO App info kafka.consumer for connector-consumer-sink-connect-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:18:58,119] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:18:58,120] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:18:58,121] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:18:58,121] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:19:08,120] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:19:08,121] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:19:08,122] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:19:08,122] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:19:18,127] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:19:18,128] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:19:18,129] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:19:18,129] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:19:28,134] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:19:28,135] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:19:28,137] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:19:28,137] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:19:38,141] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:19:38,142] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:19:38,142] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:19:38,142] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:19:48,147] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:19:48,148] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:19:48,149] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:19:48,149] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:19:58,155] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:19:58,156] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:19:58,157] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:19:58,157] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:19:59,553] INFO Successfully processed removal of connector 'sink-connect' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:578)
[2021-04-19 11:19:59,554] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector sink-connect config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1521)
[2021-04-19 11:19:59,554] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling connector-only config update by stopping connector sink-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:593)
[2021-04-19 11:19:59,555] INFO Stopping connector sink-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-19 11:19:59,555] INFO Scheduled shutdown for WorkerConnector{id=sink-connect} (org.apache.kafka.connect.runtime.WorkerConnector:249)
[2021-04-19 11:19:59,556] INFO Completed shutdown for WorkerConnector{id=sink-connect} (org.apache.kafka.connect.runtime.WorkerConnector:269)
[2021-04-19 11:19:59,559] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:19:59,559] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:19:59,564] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=46, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:19:59,570] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=46, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:19:59,571] INFO Stopping connector sink-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-19 11:19:59,571] INFO Stopping task sink-connect-0 (org.apache.kafka.connect.runtime.Worker:836)
[2021-04-19 11:19:59,571] WARN Ignoring stop request for unowned connector sink-connect (org.apache.kafka.connect.runtime.Worker:390)
[2021-04-19 11:19:59,572] WARN Ignoring await stop request for non-present connector sink-connect (org.apache.kafka.connect.runtime.Worker:415)
[2021-04-19 11:19:59,572] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1767)
[2021-04-19 11:19:59,581] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1786)
[2021-04-19 11:19:59,581] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 46 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=55, connectorIds=[source-connect, signup-connect], taskIds=[source-connect-0, signup-connect-0], revokedConnectorIds=[sink-connect], revokedTaskIds=[sink-connect-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:19:59,582] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 55 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:19:59,582] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:19:59,582] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:19:59,582] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:19:59,583] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=47, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:19:59,585] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=47, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:19:59,586] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 47 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=55, connectorIds=[source-connect, signup-connect], taskIds=[source-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:19:59,586] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 55 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:19:59,586] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:20:04,742] INFO Successfully processed removal of connector 'source-connect' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:578)
[2021-04-19 11:20:04,743] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector source-connect config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1521)
[2021-04-19 11:20:04,743] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling connector-only config update by stopping connector source-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:593)
[2021-04-19 11:20:04,743] INFO Stopping connector source-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-19 11:20:04,743] INFO Scheduled shutdown for WorkerConnector{id=source-connect} (org.apache.kafka.connect.runtime.WorkerConnector:249)
[2021-04-19 11:20:04,743] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:176)
[2021-04-19 11:20:04,744] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2021-04-19 11:20:04,744] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:20:04,745] INFO Completed shutdown for WorkerConnector{id=source-connect} (org.apache.kafka.connect.runtime.WorkerConnector:269)
[2021-04-19 11:20:04,745] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:20:04,745] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:20:04,748] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=48, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:20:04,756] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=48, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:20:04,757] INFO Stopping connector source-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-19 11:20:04,757] WARN Ignoring stop request for unowned connector source-connect (org.apache.kafka.connect.runtime.Worker:390)
[2021-04-19 11:20:04,757] INFO Stopping task source-connect-0 (org.apache.kafka.connect.runtime.Worker:836)
[2021-04-19 11:20:04,757] WARN Ignoring await stop request for non-present connector source-connect (org.apache.kafka.connect.runtime.Worker:415)
[2021-04-19 11:20:04,758] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:317)
[2021-04-19 11:20:04,785] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:324)
[2021-04-19 11:20:04,785] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:20:04,786] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:20:04,786] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:20:04,786] INFO [Producer clientId=connector-producer-source-connect-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1205)
[2021-04-19 11:20:04,787] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:20:04,787] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:20:04,787] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:20:04,787] INFO App info kafka.producer for connector-producer-source-connect-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:20:04,790] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1767)
[2021-04-19 11:20:04,810] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1786)
[2021-04-19 11:20:04,812] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 48 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=57, connectorIds=[signup-connect], taskIds=[signup-connect-0], revokedConnectorIds=[source-connect], revokedTaskIds=[source-connect-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:20:04,813] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 57 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:20:04,813] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:20:04,813] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:20:04,813] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:20:04,817] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=49, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:20:04,820] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=49, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:20:04,821] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 49 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=57, connectorIds=[signup-connect], taskIds=[signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:20:04,821] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 57 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:20:04,821] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:20:08,162] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:20:08,164] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:20:15,894] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:361)
[2021-04-19 11:20:15,901] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector source-connect config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1534)
[2021-04-19 11:20:15,902] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:20:15,902] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:20:15,904] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=50, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:20:15,910] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=50, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:20:15,910] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 50 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=58, connectorIds=[source-connect, signup-connect], taskIds=[signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:20:15,910] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 58 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:20:15,911] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector source-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1299)
[2021-04-19 11:20:15,911] INFO Creating connector source-connect of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:274)
[2021-04-19 11:20:15,911] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-19 11:20:15,912] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:20:15,913] INFO Instantiated connector source-connect with version 10.1.0 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:284)
[2021-04-19 11:20:15,914] INFO Finished creating connector source-connect (org.apache.kafka.connect.runtime.Worker:310)
[2021-04-19 11:20:15,914] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:20:15,914] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2021-04-19 11:20:15,914] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [users]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.initial = null
	topic.prefix = market_
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:361)
[2021-04-19 11:20:15,918] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:20:15,922] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2021-04-19 11:20:15,924] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-19 11:20:15,924] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:20:16,430] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [source-connect-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1549)
[2021-04-19 11:20:16,438] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling task config update by restarting tasks [] (org.apache.kafka.connect.runtime.distributed.DistributedHerder:647)
[2021-04-19 11:20:16,439] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:20:16,439] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:20:16,442] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=51, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:20:16,446] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=51, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:20:16,447] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 51 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=60, connectorIds=[source-connect, signup-connect], taskIds=[source-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:20:16,447] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 60 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:20:16,447] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task source-connect-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1258)
[2021-04-19 11:20:16,447] INFO Creating task source-connect-0 (org.apache.kafka.connect.runtime.Worker:509)
[2021-04-19 11:20:16,448] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-04-19 11:20:16,448] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:20:16,448] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-04-19 11:20:16,448] INFO Instantiated task source-connect-0 with version 10.1.0 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-04-19 11:20:16,449] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:20:16,449] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task source-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:537)
[2021-04-19 11:20:16,450] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:20:16,450] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task source-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:543)
[2021-04-19 11:20:16,450] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task source-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-04-19 11:20:16,457] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-19 11:20:16,457] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:20:16,457] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:606)
[2021-04-19 11:20:16,458] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-source-connect-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:361)
[2021-04-19 11:20:16,464] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:20:16,464] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:20:16,464] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:20:16,464] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:20:16,464] INFO Kafka startTimeMs: 1618798816464 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:20:16,465] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:20:16,466] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:85)
[2021-04-19 11:20:16,468] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [users]
	tables = [`potato`.`users`]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.initial = null
	topic.prefix = market_
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:361)
[2021-04-19 11:20:16,469] INFO Using JDBC dialect MySql (io.confluent.connect.jdbc.source.JdbcSourceTask:102)
[2021-04-19 11:20:16,471] INFO [Producer clientId=connector-producer-source-connect-0] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:20:16,609] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:20:16,627] INFO Found offset {{table=users}=null, {protocol=1, table=potato.users}={incrementing=5}} for partition {protocol=1, table=potato.users} (io.confluent.connect.jdbc.source.JdbcSourceTask:193)
[2021-04-19 11:20:16,627] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:261)
[2021-04-19 11:20:16,627] INFO WorkerSourceTask{id=source-connect-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:233)
[2021-04-19 11:20:16,628] INFO Begin using SQL query: SELECT * FROM `potato`.`users` WHERE `potato`.`users`.`id` > ? ORDER BY `potato`.`users`.`id` ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2021-04-19 11:20:18,172] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:20:18,174] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:20:26,234] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:361)
[2021-04-19 11:20:26,250] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector sink-connect config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1534)
[2021-04-19 11:20:26,468] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:20:26,469] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:20:26,757] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:20:26,757] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:20:26,761] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=52, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:20:26,765] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=52, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:20:26,765] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 52 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=61, connectorIds=[sink-connect, source-connect, signup-connect], taskIds=[source-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:20:26,766] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 61 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:20:26,767] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector sink-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1299)
[2021-04-19 11:20:26,768] INFO Creating connector sink-connect of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:274)
[2021-04-19 11:20:26,768] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-19 11:20:26,769] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:20:26,772] INFO Instantiated connector sink-connect with version 10.1.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:284)
[2021-04-19 11:20:26,772] INFO Finished creating connector sink-connect (org.apache.kafka.connect.runtime.Worker:310)
[2021-04-19 11:20:26,772] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:20:26,776] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-19 11:20:26,777] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:20:26,777] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2021-04-19 11:20:27,282] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [sink-connect-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1549)
[2021-04-19 11:20:27,283] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling task config update by restarting tasks [] (org.apache.kafka.connect.runtime.distributed.DistributedHerder:647)
[2021-04-19 11:20:27,283] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:20:27,283] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:20:27,286] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=53, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:20:27,290] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=53, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:20:27,290] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 53 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=63, connectorIds=[sink-connect, source-connect, signup-connect], taskIds=[sink-connect-0, source-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:20:27,290] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 63 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:20:27,290] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task sink-connect-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1258)
[2021-04-19 11:20:27,291] INFO Creating task sink-connect-0 (org.apache.kafka.connect.runtime.Worker:509)
[2021-04-19 11:20:27,292] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-04-19 11:20:27,292] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:20:27,292] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-04-19 11:20:27,292] INFO Instantiated task sink-connect-0 with version 10.1.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-04-19 11:20:27,292] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:20:27,292] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:537)
[2021-04-19 11:20:27,293] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:20:27,293] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:543)
[2021-04-19 11:20:27,293] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-04-19 11:20:27,293] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-04-19 11:20:27,293] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-19 11:20:27,294] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:20:27,294] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-connect-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-connect
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-04-19 11:20:27,299] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:20:27,299] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:20:27,299] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:20:27,299] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:20:27,299] INFO Kafka startTimeMs: 1618798827299 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:20:27,301] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:20:27,302] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Subscribed to topic(s): market_users (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-04-19 11:20:27,302] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:48)
[2021-04-19 11:20:27,303] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:361)
[2021-04-19 11:20:27,304] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:20:27,304] INFO WorkerSinkTask{id=sink-connect-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-04-19 11:20:27,310] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:20:27,312] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-04-19 11:20:27,314] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:20:27,318] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:20:27,323] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Successfully joined group with generation Generation{generationId=5, memberId='connector-consumer-sink-connect-0-6decda54-1d37-4efa-97e4-96bd889176af', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:20:27,327] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Finished assignment for group at generation 5: {connector-consumer-sink-connect-0-6decda54-1d37-4efa-97e4-96bd889176af=Assignment(partitions=[market_users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2021-04-19 11:20:27,332] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Successfully synced group in generation Generation{generationId=5, memberId='connector-consumer-sink-connect-0-6decda54-1d37-4efa-97e4-96bd889176af', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:20:27,332] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Notifying assignor about the new Assignment(partitions=[market_users-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-04-19 11:20:27,332] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Adding newly assigned partitions: market_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-04-19 11:20:27,334] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Setting offset for partition market_users-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:820)
[2021-04-19 11:20:27,346] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:20:27,349] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:20:27,351] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:20:27,353] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:20:27,374] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:20:27,377] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:20:27,381] WARN Write of 7 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:20:27,382] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:20:27,382] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:20:27,382] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:20:28,178] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:20:28,180] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:20:30,388] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:20:30,401] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:20:30,407] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:20:30,415] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:20:30,430] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:20:30,433] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:20:30,441] WARN Write of 7 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:20:30,442] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:20:30,443] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:20:30,443] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:20:33,447] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:20:33,460] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:20:33,470] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:20:33,477] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:20:33,489] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:20:33,492] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:20:33,499] WARN Write of 7 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:20:33,500] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:20:33,501] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:20:33,501] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:20:36,473] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:20:36,474] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:20:36,506] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:20:36,511] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:20:36,519] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:20:36,523] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:20:36,530] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:20:36,533] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:20:36,539] WARN Write of 7 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:20:36,540] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:20:36,541] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:20:36,541] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:20:37,302] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:20:37,314] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:20:37,327] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:20:37,333] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:20:37,343] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:20:37,351] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:20:37,358] WARN Write of 7 records failed, remainingRetries=6 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:20:37,358] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:20:37,359] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:20:37,359] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:20:38,185] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:20:38,185] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:20:40,361] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:20:40,367] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:20:40,373] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:20:40,381] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:20:40,392] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:20:40,396] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:20:40,404] WARN Write of 7 records failed, remainingRetries=5 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:20:40,405] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:20:40,405] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:20:40,405] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:20:43,412] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:20:43,422] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:20:43,428] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:20:43,433] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:20:43,444] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:20:43,447] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:20:43,456] WARN Write of 7 records failed, remainingRetries=4 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:20:43,456] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:20:43,457] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:20:43,457] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:20:46,463] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:20:46,475] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:20:46,479] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:20:46,479] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:20:46,480] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:20:46,484] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:20:46,494] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:20:46,498] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:20:46,504] WARN Write of 7 records failed, remainingRetries=3 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:20:46,504] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:20:46,505] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:20:46,505] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:20:47,365] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:20:47,373] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:20:47,377] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:20:47,381] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:20:47,395] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:20:47,400] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:20:47,404] WARN Write of 7 records failed, remainingRetries=2 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:20:47,404] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:20:47,405] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:20:47,405] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:20:48,193] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:20:48,194] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:20:50,406] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:20:50,413] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:20:50,419] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:20:50,423] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:20:50,435] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:20:50,439] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:20:50,442] WARN Write of 7 records failed, remainingRetries=1 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:20:50,443] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:20:50,444] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:20:50,444] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:20:53,449] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:20:53,456] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:20:53,467] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:20:53,481] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:20:53,492] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:20:53,498] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:20:53,503] WARN Write of 7 records failed, remainingRetries=0 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:20:53,504] ERROR Failing task after exhausting retries; encountered 2 exceptions on last write attempt. For complete details on each exception, please enable DEBUG logging. (io.confluent.connect.jdbc.sink.JdbcSinkTask:113)
[2021-04-19 11:20:53,504] ERROR WorkerSinkTask{id=sink-connect-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
 (org.apache.kafka.connect.runtime.WorkerSinkTask:612)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:122)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:20:53,505] ERROR WorkerSinkTask{id=sink-connect-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:614)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:122)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	... 10 more
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:20:53,505] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:161)
[2021-04-19 11:20:53,505] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:20:53,507] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Revoke previously assigned partitions market_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2021-04-19 11:20:53,507] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Member connector-consumer-sink-connect-0-6decda54-1d37-4efa-97e4-96bd889176af sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-04-19 11:20:53,514] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:20:53,515] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:20:53,515] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:20:53,520] INFO App info kafka.consumer for connector-consumer-sink-connect-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:20:56,481] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:20:56,482] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:20:58,195] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:20:58,196] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:21:06,485] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:21:06,486] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:21:08,201] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:21:08,202] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:21:16,490] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:21:16,491] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:21:18,208] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:21:18,208] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:21:26,496] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:21:26,498] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:21:28,212] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:21:28,213] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:21:36,500] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:21:36,501] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:21:38,218] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:21:38,219] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:21:40,354] INFO Successfully processed removal of connector 'sink-connect' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:578)
[2021-04-19 11:21:40,354] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector sink-connect config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1521)
[2021-04-19 11:21:40,355] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling connector-only config update by stopping connector sink-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:593)
[2021-04-19 11:21:40,355] INFO Stopping connector sink-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-19 11:21:40,355] INFO Scheduled shutdown for WorkerConnector{id=sink-connect} (org.apache.kafka.connect.runtime.WorkerConnector:249)
[2021-04-19 11:21:40,356] INFO Completed shutdown for WorkerConnector{id=sink-connect} (org.apache.kafka.connect.runtime.WorkerConnector:269)
[2021-04-19 11:21:40,357] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:21:40,357] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:21:40,359] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=54, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:21:40,364] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=54, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:21:40,365] INFO Stopping connector sink-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-19 11:21:40,365] INFO Stopping task sink-connect-0 (org.apache.kafka.connect.runtime.Worker:836)
[2021-04-19 11:21:40,365] WARN Ignoring stop request for unowned connector sink-connect (org.apache.kafka.connect.runtime.Worker:390)
[2021-04-19 11:21:40,365] WARN Ignoring await stop request for non-present connector sink-connect (org.apache.kafka.connect.runtime.Worker:415)
[2021-04-19 11:21:40,366] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1767)
[2021-04-19 11:21:40,369] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1786)
[2021-04-19 11:21:40,369] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 54 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=65, connectorIds=[source-connect, signup-connect], taskIds=[source-connect-0, signup-connect-0], revokedConnectorIds=[sink-connect], revokedTaskIds=[sink-connect-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:21:40,370] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 65 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:21:40,370] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:21:40,370] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:21:40,370] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:21:40,372] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=55, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:21:40,376] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=55, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:21:40,377] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 55 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=65, connectorIds=[source-connect, signup-connect], taskIds=[source-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:21:40,378] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 65 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:21:40,378] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:21:44,119] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:361)
[2021-04-19 11:21:44,126] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector sink-connect config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1534)
[2021-04-19 11:21:44,126] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:21:44,126] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:21:44,128] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=56, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:21:44,133] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=56, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:21:44,134] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 56 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=66, connectorIds=[sink-connect, source-connect, signup-connect], taskIds=[source-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:21:44,134] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 66 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:21:44,135] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector sink-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1299)
[2021-04-19 11:21:44,135] INFO Creating connector sink-connect of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:274)
[2021-04-19 11:21:44,136] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-19 11:21:44,136] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:21:44,138] INFO Instantiated connector sink-connect with version 10.1.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:284)
[2021-04-19 11:21:44,139] INFO Finished creating connector sink-connect (org.apache.kafka.connect.runtime.Worker:310)
[2021-04-19 11:21:44,140] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:21:44,141] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-19 11:21:44,142] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:21:44,142] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2021-04-19 11:21:44,644] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [sink-connect-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1549)
[2021-04-19 11:21:44,644] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling task config update by restarting tasks [] (org.apache.kafka.connect.runtime.distributed.DistributedHerder:647)
[2021-04-19 11:21:44,645] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:21:44,645] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:21:44,647] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=57, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:21:44,652] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=57, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:21:44,652] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 57 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=68, connectorIds=[sink-connect, source-connect, signup-connect], taskIds=[sink-connect-0, source-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:21:44,653] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 68 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:21:44,653] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task sink-connect-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1258)
[2021-04-19 11:21:44,653] INFO Creating task sink-connect-0 (org.apache.kafka.connect.runtime.Worker:509)
[2021-04-19 11:21:44,655] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-04-19 11:21:44,655] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:21:44,655] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-04-19 11:21:44,655] INFO Instantiated task sink-connect-0 with version 10.1.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-04-19 11:21:44,657] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:21:44,657] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:537)
[2021-04-19 11:21:44,660] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:21:44,660] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:543)
[2021-04-19 11:21:44,660] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-04-19 11:21:44,661] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-04-19 11:21:44,661] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-19 11:21:44,661] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-connect
	predicates = []
	tasks.max = 1
	topics = [market_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:21:44,662] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-connect-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-connect
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-04-19 11:21:44,668] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:21:44,668] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:21:44,668] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:21:44,668] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:21:44,668] INFO Kafka startTimeMs: 1618798904668 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:21:44,669] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:21:44,670] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Subscribed to topic(s): market_users (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-04-19 11:21:44,670] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:48)
[2021-04-19 11:21:44,670] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:361)
[2021-04-19 11:21:44,671] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:21:44,671] INFO WorkerSinkTask{id=sink-connect-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-04-19 11:21:44,676] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:21:44,677] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-04-19 11:21:44,677] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:21:44,686] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:21:44,691] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Successfully joined group with generation Generation{generationId=7, memberId='connector-consumer-sink-connect-0-6bae2131-d200-4d51-9b85-11766f2a8d8b', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:21:44,691] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Finished assignment for group at generation 7: {connector-consumer-sink-connect-0-6bae2131-d200-4d51-9b85-11766f2a8d8b=Assignment(partitions=[market_users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2021-04-19 11:21:44,696] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Successfully synced group in generation Generation{generationId=7, memberId='connector-consumer-sink-connect-0-6bae2131-d200-4d51-9b85-11766f2a8d8b', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:21:44,696] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Notifying assignor about the new Assignment(partitions=[market_users-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-04-19 11:21:44,696] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Adding newly assigned partitions: market_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-04-19 11:21:44,697] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Setting offset for partition market_users-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:820)
[2021-04-19 11:21:44,707] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:21:44,714] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:21:44,716] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:21:44,718] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:21:44,726] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:21:44,727] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:21:44,732] WARN Write of 7 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:21:44,732] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:21:44,732] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:21:44,732] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:21:46,505] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:21:46,506] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:21:47,739] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:21:47,745] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:21:47,750] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:21:47,755] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:21:47,796] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:21:47,798] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:21:47,801] WARN Write of 7 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:21:47,801] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:21:47,802] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:21:47,802] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:21:48,223] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:21:48,224] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:21:50,804] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:21:50,813] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:21:50,818] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:21:50,826] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:21:50,836] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:21:50,840] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:21:50,844] WARN Write of 7 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:21:50,845] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:21:50,846] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:21:50,846] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:21:53,852] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:21:53,857] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:21:53,861] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:21:53,871] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:21:53,881] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:21:53,884] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:21:53,890] WARN Write of 7 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:21:53,890] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:21:53,891] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:21:53,891] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:21:54,673] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:21:54,686] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:21:54,690] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:21:54,694] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:21:54,703] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:21:54,706] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:21:54,709] WARN Write of 7 records failed, remainingRetries=6 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:21:54,709] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:21:54,710] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:21:54,710] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:21:56,511] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:21:56,512] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:21:57,716] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:21:57,722] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:21:57,726] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:21:57,729] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:21:57,738] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:21:57,742] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:21:57,745] WARN Write of 7 records failed, remainingRetries=5 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:21:57,745] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:21:57,746] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:21:57,746] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:21:58,214] INFO Successfully processed removal of connector 'source-connect' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:578)
[2021-04-19 11:21:58,215] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector source-connect config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1521)
[2021-04-19 11:21:58,215] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling connector-only config update by stopping connector source-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:593)
[2021-04-19 11:21:58,215] INFO Stopping connector source-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-19 11:21:58,215] INFO Scheduled shutdown for WorkerConnector{id=source-connect} (org.apache.kafka.connect.runtime.WorkerConnector:249)
[2021-04-19 11:21:58,215] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:176)
[2021-04-19 11:21:58,216] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2021-04-19 11:21:58,216] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:21:58,217] INFO Completed shutdown for WorkerConnector{id=source-connect} (org.apache.kafka.connect.runtime.WorkerConnector:269)
[2021-04-19 11:21:58,220] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:21:58,221] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:21:58,224] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=58, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:21:58,226] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:21:58,226] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:21:58,229] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=58, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:21:58,230] INFO Stopping connector source-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-19 11:21:58,230] WARN Ignoring stop request for unowned connector source-connect (org.apache.kafka.connect.runtime.Worker:390)
[2021-04-19 11:21:58,230] INFO Stopping task source-connect-0 (org.apache.kafka.connect.runtime.Worker:836)
[2021-04-19 11:21:58,230] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:317)
[2021-04-19 11:21:58,230] WARN Ignoring await stop request for non-present connector source-connect (org.apache.kafka.connect.runtime.Worker:415)
[2021-04-19 11:21:58,318] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:324)
[2021-04-19 11:21:58,318] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:21:58,319] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:21:58,319] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:21:58,319] INFO [Producer clientId=connector-producer-source-connect-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1205)
[2021-04-19 11:21:58,321] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:21:58,321] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:21:58,321] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:21:58,321] INFO App info kafka.producer for connector-producer-source-connect-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:21:58,323] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1767)
[2021-04-19 11:21:58,325] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1786)
[2021-04-19 11:21:58,325] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 58 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=70, connectorIds=[sink-connect, signup-connect], taskIds=[sink-connect-0, signup-connect-0], revokedConnectorIds=[source-connect], revokedTaskIds=[source-connect-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:21:58,326] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 70 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:21:58,326] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:21:58,326] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:21:58,326] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:21:58,328] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=59, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:21:58,332] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=59, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:21:58,333] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 59 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=70, connectorIds=[sink-connect, signup-connect], taskIds=[sink-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:21:58,333] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 70 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:21:58,333] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:22:00,748] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:22:00,757] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:22:00,762] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:22:00,769] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:22:00,787] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:22:00,789] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:22:00,792] WARN Write of 7 records failed, remainingRetries=4 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:22:00,793] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:22:00,794] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:22:00,794] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:22:03,800] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:22:03,809] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:22:03,820] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:22:03,829] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:22:03,837] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:22:03,840] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:22:03,843] WARN Write of 7 records failed, remainingRetries=3 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:22:03,843] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:22:03,844] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:22:03,844] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:22:04,717] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:22:04,725] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:22:04,733] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:22:04,737] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:22:04,746] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:22:04,749] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:22:04,760] WARN Write of 7 records failed, remainingRetries=2 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:22:04,760] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:22:04,761] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:22:04,761] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:22:07,766] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:22:07,773] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:22:07,780] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:22:07,784] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:22:07,794] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:22:07,797] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:22:07,801] WARN Write of 7 records failed, remainingRetries=1 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:22:07,801] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:22:07,802] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:22:07,802] ERROR WorkerSinkTask{id=sink-connect-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:605)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:22:08,232] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:22:08,233] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:22:10,207] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:361)
[2021-04-19 11:22:10,215] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector source-connect config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1534)
[2021-04-19 11:22:10,216] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:22:10,216] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:22:10,218] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=60, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:22:10,221] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=60, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:22:10,221] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 60 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=71, connectorIds=[source-connect, sink-connect, signup-connect], taskIds=[sink-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:22:10,222] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 71 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:22:10,222] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector source-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1299)
[2021-04-19 11:22:10,223] INFO Creating connector source-connect of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:274)
[2021-04-19 11:22:10,224] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-19 11:22:10,224] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:22:10,224] INFO Instantiated connector source-connect with version 10.1.0 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:284)
[2021-04-19 11:22:10,224] INFO Finished creating connector source-connect (org.apache.kafka.connect.runtime.Worker:310)
[2021-04-19 11:22:10,224] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2021-04-19 11:22:10,224] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:22:10,225] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [users]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.initial = null
	topic.prefix = market_
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:361)
[2021-04-19 11:22:10,225] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:22:10,229] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2021-04-19 11:22:10,230] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-19 11:22:10,230] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:22:10,738] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [source-connect-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1549)
[2021-04-19 11:22:10,738] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling task config update by restarting tasks [] (org.apache.kafka.connect.runtime.distributed.DistributedHerder:647)
[2021-04-19 11:22:10,739] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:22:10,739] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:22:10,741] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=61, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:22:10,744] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=61, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:22:10,744] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 61 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=73, connectorIds=[source-connect, sink-connect, signup-connect], taskIds=[source-connect-0, sink-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:22:10,745] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 73 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:22:10,745] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task source-connect-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1258)
[2021-04-19 11:22:10,745] INFO Creating task source-connect-0 (org.apache.kafka.connect.runtime.Worker:509)
[2021-04-19 11:22:10,746] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-04-19 11:22:10,747] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:22:10,747] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-04-19 11:22:10,747] INFO Instantiated task source-connect-0 with version 10.1.0 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-04-19 11:22:10,747] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:22:10,747] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task source-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:537)
[2021-04-19 11:22:10,750] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:22:10,750] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task source-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:543)
[2021-04-19 11:22:10,751] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task source-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-04-19 11:22:10,758] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-19 11:22:10,759] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:22:10,760] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:606)
[2021-04-19 11:22:10,760] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-source-connect-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:361)
[2021-04-19 11:22:10,765] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:22:10,765] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:22:10,765] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:22:10,765] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:22:10,765] INFO Kafka startTimeMs: 1618798930765 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:22:10,767] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:22:10,767] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:85)
[2021-04-19 11:22:10,771] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [users]
	tables = [`potato`.`users`]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.initial = null
	topic.prefix = market_
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:361)
[2021-04-19 11:22:10,773] INFO Using JDBC dialect MySql (io.confluent.connect.jdbc.source.JdbcSourceTask:102)
[2021-04-19 11:22:10,778] INFO [Producer clientId=connector-producer-source-connect-0] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:22:10,805] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:22:10,808] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:22:10,811] INFO Checking MySql dialect for existence of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:22:10,815] INFO Using MySql dialect TABLE "market_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:22:10,822] INFO Checking MySql dialect for type of TABLE "market_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:22:10,824] INFO Setting metadata for table "market_users" to Table{name='"market_users"', type=TABLE columns=[Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:22:10,826] WARN Write of 7 records failed, remainingRetries=0 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
	at jdk.internal.reflect.GeneratedConstructorAccessor24.newInstance(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)
	at com.mysql.cj.util.Util.getInstance(Util.java:167)
	at com.mysql.cj.util.Util.getInstance(Util.java:174)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:221)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:187)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)
	... 17 more
[2021-04-19 11:22:10,827] ERROR Failing task after exhausting retries; encountered 2 exceptions on last write attempt. For complete details on each exception, please enable DEBUG logging. (io.confluent.connect.jdbc.sink.JdbcSinkTask:113)
[2021-04-19 11:22:10,827] ERROR WorkerSinkTask{id=sink-connect-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'
 (org.apache.kafka.connect.runtime.WorkerSinkTask:612)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:122)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:22:10,827] ERROR WorkerSinkTask{id=sink-connect-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:614)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:329)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:185)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:122)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:586)
	... 10 more
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Duplicate entry '5' for key 'PRIMARY'
java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '5' for key 'PRIMARY'

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2021-04-19 11:22:10,827] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:161)
[2021-04-19 11:22:10,827] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:22:10,828] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Revoke previously assigned partitions market_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2021-04-19 11:22:10,828] INFO [Consumer clientId=connector-consumer-sink-connect-0, groupId=connect-sink-connect] Member connector-consumer-sink-connect-0-6bae2131-d200-4d51-9b85-11766f2a8d8b sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-04-19 11:22:10,830] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:22:10,830] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:22:10,830] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:22:10,831] INFO App info kafka.consumer for connector-consumer-sink-connect-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:22:10,995] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:22:11,022] INFO Found offset {{table=users}=null, {protocol=1, table=potato.users}={incrementing=5}} for partition {protocol=1, table=potato.users} (io.confluent.connect.jdbc.source.JdbcSourceTask:193)
[2021-04-19 11:22:11,022] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:261)
[2021-04-19 11:22:11,022] INFO WorkerSourceTask{id=source-connect-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:233)
[2021-04-19 11:22:11,023] INFO Begin using SQL query: SELECT * FROM `potato`.`users` WHERE `potato`.`users`.`id` > ? ORDER BY `potato`.`users`.`id` ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2021-04-19 11:22:18,238] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:22:18,239] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:22:20,777] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:22:20,778] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:22:28,241] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:22:28,242] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:22:30,783] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:22:30,784] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:22:38,247] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:22:38,247] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:22:40,790] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:22:40,792] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:22:48,252] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:22:48,253] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:22:50,797] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:22:50,798] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:22:58,259] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:22:58,260] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:23:00,804] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:23:00,804] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:23:08,265] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:23:08,267] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:23:10,807] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:23:10,807] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:23:18,269] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:23:18,269] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:23:20,813] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:23:20,814] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:23:28,273] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:23:28,274] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:23:30,820] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:23:30,821] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:23:38,280] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:23:38,281] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:23:40,827] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:23:40,827] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:23:48,286] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:23:48,287] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:23:50,831] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:23:50,832] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:23:58,294] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:23:58,295] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:24:00,836] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:24:00,837] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:24:08,302] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:24:08,304] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:24:10,843] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:24:10,848] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:24:18,307] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:24:18,310] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:24:20,858] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:24:20,858] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:24:24,416] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:361)
[2021-04-19 11:24:24,458] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector login-source-connect config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1534)
[2021-04-19 11:24:24,458] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:24:24,458] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:24:24,471] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=62, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:24:24,478] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=62, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:24:24,478] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 62 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=74, connectorIds=[login-source-connect, source-connect, sink-connect, signup-connect], taskIds=[source-connect-0, sink-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:24:24,478] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 74 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:24:24,478] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector login-source-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1299)
[2021-04-19 11:24:24,479] INFO Creating connector login-source-connect of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:274)
[2021-04-19 11:24:24,479] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = login-source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-19 11:24:24,479] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = login-source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:24:24,480] INFO Instantiated connector login-source-connect with version 10.1.0 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:284)
[2021-04-19 11:24:24,480] INFO Finished creating connector login-source-connect (org.apache.kafka.connect.runtime.Worker:310)
[2021-04-19 11:24:24,480] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:24:24,481] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2021-04-19 11:24:24,481] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [users]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.initial = null
	topic.prefix = login_
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:361)
[2021-04-19 11:24:24,481] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:24:24,486] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2021-04-19 11:24:24,486] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = login-source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-19 11:24:24,486] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = login-source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:24:24,984] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [login-source-connect-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1549)
[2021-04-19 11:24:24,984] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling task config update by restarting tasks [] (org.apache.kafka.connect.runtime.distributed.DistributedHerder:647)
[2021-04-19 11:24:24,984] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:24:24,984] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:24:24,986] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=63, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:24:24,990] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=63, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:24:24,990] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 63 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=76, connectorIds=[login-source-connect, source-connect, sink-connect, signup-connect], taskIds=[login-source-connect-0, source-connect-0, sink-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:24:24,990] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 76 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:24:24,991] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task login-source-connect-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1258)
[2021-04-19 11:24:24,991] INFO Creating task login-source-connect-0 (org.apache.kafka.connect.runtime.Worker:509)
[2021-04-19 11:24:24,992] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = login-source-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-04-19 11:24:24,992] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = login-source-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:24:24,993] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-04-19 11:24:24,993] INFO Instantiated task login-source-connect-0 with version 10.1.0 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-04-19 11:24:24,994] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:24:24,994] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task login-source-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:537)
[2021-04-19 11:24:24,994] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:24:24,994] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task login-source-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:543)
[2021-04-19 11:24:24,995] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task login-source-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-04-19 11:24:24,996] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = login-source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:361)
[2021-04-19 11:24:24,996] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = login-source-connect
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:24:24,996] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:606)
[2021-04-19 11:24:24,998] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-login-source-connect-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:361)
[2021-04-19 11:24:25,003] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:24:25,003] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:369)
[2021-04-19 11:24:25,003] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:24:25,004] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:24:25,004] INFO Kafka startTimeMs: 1618799065003 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:24:25,005] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:24:25,006] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:85)
[2021-04-19 11:24:25,006] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [users]
	tables = [`potato`.`users`]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.initial = null
	topic.prefix = login_
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:361)
[2021-04-19 11:24:25,007] INFO Using JDBC dialect MySql (io.confluent.connect.jdbc.source.JdbcSourceTask:102)
[2021-04-19 11:24:25,024] INFO [Producer clientId=connector-producer-login-source-connect-0] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:24:25,503] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:24:25,528] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:261)
[2021-04-19 11:24:25,529] INFO WorkerSourceTask{id=login-source-connect-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:233)
[2021-04-19 11:24:25,529] INFO Begin using SQL query: SELECT * FROM `potato`.`users` WHERE `potato`.`users`.`id` > ? ORDER BY `potato`.`users`.`id` ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2021-04-19 11:24:28,317] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:24:28,318] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:24:30,865] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:24:30,865] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:24:35,010] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:24:35,010] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:24:35,023] INFO WorkerSourceTask{id=login-source-connect-0} Finished commitOffsets successfully in 12 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:574)
[2021-04-19 11:24:38,324] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:24:38,325] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:24:40,872] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:24:40,873] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:24:45,024] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:24:45,024] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:24:48,332] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:24:48,333] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:24:50,878] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:24:50,879] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:24:55,029] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:24:55,030] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:24:58,335] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:24:58,335] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:00,884] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:00,885] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:05,035] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:05,035] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:08,337] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:08,339] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:10,889] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:10,890] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:15,038] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:15,038] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:18,345] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:18,346] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:20,082] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:361)
[2021-04-19 11:25:20,090] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector login-sink-connect config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1534)
[2021-04-19 11:25:20,090] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:25:20,090] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:25:20,094] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=64, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:25:20,098] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=64, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:25:20,098] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 64 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=77, connectorIds=[login-sink-connect, login-source-connect, source-connect, sink-connect, signup-connect], taskIds=[login-source-connect-0, source-connect-0, sink-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:25:20,098] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 77 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:25:20,099] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector login-sink-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1299)
[2021-04-19 11:25:20,099] INFO Creating connector login-sink-connect of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:274)
[2021-04-19 11:25:20,099] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = login-sink-connect
	predicates = []
	tasks.max = 1
	topics = [login_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-19 11:25:20,099] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = login-sink-connect
	predicates = []
	tasks.max = 1
	topics = [login_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:25:20,100] INFO Instantiated connector login-sink-connect with version 10.1.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:284)
[2021-04-19 11:25:20,100] INFO Finished creating connector login-sink-connect (org.apache.kafka.connect.runtime.Worker:310)
[2021-04-19 11:25:20,100] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:25:20,101] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = login-sink-connect
	predicates = []
	tasks.max = 1
	topics = [login_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-19 11:25:20,101] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = login-sink-connect
	predicates = []
	tasks.max = 1
	topics = [login_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:25:20,101] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2021-04-19 11:25:20,608] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [login-sink-connect-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1549)
[2021-04-19 11:25:20,609] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling task config update by restarting tasks [] (org.apache.kafka.connect.runtime.distributed.DistributedHerder:647)
[2021-04-19 11:25:20,609] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:225)
[2021-04-19 11:25:20,609] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:25:20,611] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=65, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:25:20,615] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=65, memberId='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:25:20,615] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 65 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c', leaderUrl='http://218.38.137.28:8083/', offset=79, connectorIds=[login-sink-connect, login-source-connect, source-connect, sink-connect, signup-connect], taskIds=[login-sink-connect-0, login-source-connect-0, source-connect-0, sink-connect-0, signup-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1689)
[2021-04-19 11:25:20,615] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 79 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
[2021-04-19 11:25:20,615] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task login-sink-connect-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1258)
[2021-04-19 11:25:20,616] INFO Creating task login-sink-connect-0 (org.apache.kafka.connect.runtime.Worker:509)
[2021-04-19 11:25:20,616] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = login-sink-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-04-19 11:25:20,617] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = login-sink-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:25:20,617] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-04-19 11:25:20,617] INFO Instantiated task login-sink-connect-0 with version 10.1.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-04-19 11:25:20,618] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:25:20,618] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task login-sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:537)
[2021-04-19 11:25:20,618] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-04-19 11:25:20,618] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task login-sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:543)
[2021-04-19 11:25:20,618] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task login-sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-04-19 11:25:20,619] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-04-19 11:25:20,619] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = login-sink-connect
	predicates = []
	tasks.max = 1
	topics = [login_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-04-19 11:25:20,619] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = login-sink-connect
	predicates = []
	tasks.max = 1
	topics = [login_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-04-19 11:25:20,620] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-login-sink-connect-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-login-sink-connect
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-04-19 11:25:20,625] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:25:20,625] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-04-19 11:25:20,625] INFO Kafka version: 6.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-04-19 11:25:20,625] INFO Kafka commitId: 5496d92defc9bbe4 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-04-19 11:25:20,625] INFO Kafka startTimeMs: 1618799120625 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-04-19 11:25:20,627] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2021-04-19 11:25:20,628] INFO [Consumer clientId=connector-consumer-login-sink-connect-0, groupId=connect-login-sink-connect] Subscribed to topic(s): login_users (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-04-19 11:25:20,628] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:48)
[2021-04-19 11:25:20,628] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/potato
	connection.user = root
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:361)
[2021-04-19 11:25:20,628] INFO Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2021-04-19 11:25:20,628] INFO WorkerSinkTask{id=login-sink-connect-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-04-19 11:25:20,636] INFO [Consumer clientId=connector-consumer-login-sink-connect-0, groupId=connect-login-sink-connect] Cluster ID: Bv2b4BFXSv-vz440bkiGyA (org.apache.kafka.clients.Metadata:279)
[2021-04-19 11:25:20,636] INFO [Consumer clientId=connector-consumer-login-sink-connect-0, groupId=connect-login-sink-connect] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-04-19 11:25:20,637] INFO [Consumer clientId=connector-consumer-login-sink-connect-0, groupId=connect-login-sink-connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:25:20,642] INFO [Consumer clientId=connector-consumer-login-sink-connect-0, groupId=connect-login-sink-connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-04-19 11:25:20,645] INFO [Consumer clientId=connector-consumer-login-sink-connect-0, groupId=connect-login-sink-connect] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-login-sink-connect-0-03d39920-6234-4f96-8b88-3151f42ad8df', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-04-19 11:25:20,645] INFO [Consumer clientId=connector-consumer-login-sink-connect-0, groupId=connect-login-sink-connect] Finished assignment for group at generation 1: {connector-consumer-login-sink-connect-0-03d39920-6234-4f96-8b88-3151f42ad8df=Assignment(partitions=[login_users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2021-04-19 11:25:20,650] INFO [Consumer clientId=connector-consumer-login-sink-connect-0, groupId=connect-login-sink-connect] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-login-sink-connect-0-03d39920-6234-4f96-8b88-3151f42ad8df', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-04-19 11:25:20,650] INFO [Consumer clientId=connector-consumer-login-sink-connect-0, groupId=connect-login-sink-connect] Notifying assignor about the new Assignment(partitions=[login_users-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-04-19 11:25:20,650] INFO [Consumer clientId=connector-consumer-login-sink-connect-0, groupId=connect-login-sink-connect] Adding newly assigned partitions: login_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-04-19 11:25:20,652] INFO [Consumer clientId=connector-consumer-login-sink-connect-0, groupId=connect-login-sink-connect] Found no committed offset for partition login_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1354)
[2021-04-19 11:25:20,659] INFO [Consumer clientId=connector-consumer-login-sink-connect-0, groupId=connect-login-sink-connect] Resetting offset for partition login_users-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-04-19 11:25:20,671] INFO Attempting to open connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:82)
[2021-04-19 11:25:20,674] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2021-04-19 11:25:20,676] INFO Checking MySql dialect for existence of TABLE "login_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:570)
[2021-04-19 11:25:20,679] INFO Using MySql dialect TABLE "login_users" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:578)
[2021-04-19 11:25:20,687] INFO Checking MySql dialect for type of TABLE "login_users" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:840)
[2021-04-19 11:25:20,692] INFO Setting metadata for table "login_users" to Table{name='"login_users"', type=TABLE columns=[Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INT}, Column{'gender', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'email', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'birthdate', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'password', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'location', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'sellcount', isPrimaryKey=false, allowsNull=true, sqlType=INT}, Column{'nickname', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'createat', isPrimaryKey=false, allowsNull=true, sqlType=DATE}, Column{'caution', isPrimaryKey=false, allowsNull=true, sqlType=INT}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2021-04-19 11:25:20,893] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:20,894] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:25,040] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:25,043] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:28,352] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:28,354] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:30,630] INFO WorkerSinkTask{id=login-sink-connect-0} Committing offsets asynchronously using sequence number 1: {login_users-0=OffsetAndMetadata{offset=5, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:352)
[2021-04-19 11:25:30,900] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:30,900] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:35,045] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:35,046] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:38,360] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:38,360] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:40,906] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:40,906] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:45,051] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:45,052] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:48,362] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:48,364] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:50,912] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:50,913] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:55,056] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:55,057] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:25:58,367] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:25:58,367] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:00,921] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:00,922] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:05,071] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:05,072] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:08,387] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:08,387] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:10,942] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:10,943] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:15,088] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:15,089] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:18,403] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:18,404] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:20,953] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:20,954] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:25,098] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:25,099] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:28,409] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:28,409] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:30,962] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:30,963] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:35,107] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:35,108] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:38,416] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:38,417] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:40,970] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:40,971] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:45,114] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:45,115] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:48,424] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:48,425] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:50,977] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:50,978] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:55,117] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:55,117] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:26:58,429] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:26:58,430] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:00,981] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:00,984] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:05,125] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:05,126] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:08,433] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:08,434] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:10,990] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:10,991] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:15,129] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:15,130] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:18,440] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:18,440] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:20,996] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:20,997] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:25,136] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:25,136] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:28,443] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:28,444] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:31,003] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:31,003] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:35,141] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:35,142] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:38,449] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:38,450] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:38,454] INFO WorkerSourceTask{id=signup-connect-0} Finished commitOffsets successfully in 4 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:574)
[2021-04-19 11:27:40,694] INFO WorkerSinkTask{id=login-sink-connect-0} Committing offsets asynchronously using sequence number 14: {login_users-0=OffsetAndMetadata{offset=6, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:352)
[2021-04-19 11:27:41,005] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:41,005] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:41,016] INFO WorkerSourceTask{id=source-connect-0} Finished commitOffsets successfully in 11 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:574)
[2021-04-19 11:27:45,147] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:45,148] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:45,155] INFO WorkerSourceTask{id=login-source-connect-0} Finished commitOffsets successfully in 7 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:574)
[2021-04-19 11:27:48,460] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:48,461] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:51,021] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:51,022] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:55,158] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:55,159] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:27:58,466] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:27:58,467] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:01,027] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:01,028] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:05,163] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:05,163] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:08,473] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:08,473] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:11,031] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:11,032] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:15,170] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:15,171] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:18,475] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:18,477] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:21,037] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:21,038] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:25,173] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:25,173] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:28,480] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:28,480] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:31,041] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:31,042] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:35,176] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:35,177] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:38,483] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:38,483] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:41,045] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:41,046] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:45,181] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:45,182] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:48,487] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:48,488] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:51,049] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:51,050] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:55,187] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:55,188] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:28:58,490] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:28:58,491] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:01,051] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:01,052] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:05,191] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:05,192] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:08,493] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:08,496] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:11,058] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:11,060] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:15,198] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:15,199] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:18,499] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:18,500] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:21,065] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:21,066] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:25,204] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:25,204] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:28,500] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:28,500] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:31,069] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:31,071] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:35,210] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:35,211] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:38,504] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:38,505] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:41,078] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:41,079] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:45,213] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:45,213] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:48,509] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:48,510] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:51,080] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:51,081] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:55,216] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:55,216] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:29:58,516] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:29:58,516] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:01,084] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:01,085] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:05,222] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:05,222] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:08,520] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:08,521] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:11,090] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:11,091] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:15,228] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:15,229] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:18,522] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:18,523] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:21,096] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:21,097] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:25,233] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:25,234] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:28,528] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:28,530] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:31,101] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:31,102] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:35,235] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:35,236] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:38,531] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:38,531] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:41,103] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:41,104] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:45,239] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:45,241] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:48,537] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:48,538] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:51,110] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:51,110] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:55,247] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:55,248] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:30:58,543] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:30:58,544] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:01,122] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:01,123] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:05,251] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:05,251] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:08,548] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:08,550] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:11,126] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:11,127] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:15,255] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:15,255] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:18,554] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:18,555] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:21,133] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:21,134] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:25,262] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:25,265] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:28,561] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:28,562] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:31,141] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:31,142] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:35,268] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:35,269] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:38,569] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:38,570] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:41,149] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:41,149] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:45,274] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:45,274] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:48,574] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:48,575] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:51,151] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:51,151] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:55,281] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:55,282] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:31:58,579] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:31:58,580] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:01,156] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:01,157] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:05,287] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:05,288] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:08,581] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:08,581] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:11,161] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:11,162] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:15,290] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:15,291] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:18,583] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:18,584] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:21,167] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:21,167] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:25,294] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:25,296] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:28,589] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:28,595] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:31,173] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:31,173] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:35,300] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:35,302] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:38,600] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:38,601] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:41,179] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:41,179] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:45,303] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:45,304] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:48,603] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:48,604] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:51,182] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:51,183] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:55,309] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:55,309] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:32:58,608] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:32:58,609] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:01,185] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:01,186] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:05,311] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:05,311] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:08,610] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:08,611] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:11,187] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:11,188] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:15,315] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:15,316] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:18,616] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:18,618] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:21,190] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:21,191] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:25,318] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:25,319] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:28,620] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:28,621] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:31,195] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:31,195] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:35,324] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:35,325] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:38,623] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:38,623] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:41,199] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:41,200] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:45,327] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:45,328] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:48,625] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:48,626] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:51,205] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:51,205] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:55,328] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:55,329] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:33:58,628] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:33:58,629] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:01,208] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:01,209] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:05,332] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:05,333] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:08,633] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:08,633] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:11,210] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:11,211] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:15,335] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:15,336] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:18,639] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:18,640] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:21,216] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:21,216] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:25,340] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:25,342] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:28,644] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:28,645] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:31,219] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:31,220] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:35,344] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:35,345] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:38,650] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:38,652] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:41,225] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:41,226] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:45,349] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:45,351] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:48,657] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:48,658] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:51,228] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:51,229] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:55,353] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:55,355] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:34:58,661] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:34:58,662] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:01,235] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:01,236] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:05,357] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:05,357] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:08,667] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:08,667] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:11,239] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:11,240] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:15,359] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:15,361] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:18,668] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:18,668] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:21,245] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:21,246] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:25,365] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:25,366] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:28,672] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:28,673] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:31,251] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:31,252] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:35,371] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:35,385] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:38,679] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:38,688] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:41,271] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:41,280] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:45,395] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:45,396] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:48,692] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:48,693] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:51,286] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:51,287] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:55,399] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:55,401] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:35:58,694] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:35:58,694] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:01,289] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:01,289] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:05,406] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:05,407] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:08,699] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:08,700] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:11,312] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:11,322] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:15,413] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:15,414] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:18,703] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:18,705] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:21,328] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:21,329] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:25,417] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:25,418] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:28,709] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:28,710] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:31,332] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:31,333] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:35,419] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:35,420] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:38,725] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:38,736] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:41,339] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:41,341] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:45,424] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:45,424] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:48,742] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:48,743] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:51,346] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:51,347] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:55,430] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:55,431] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:36:58,748] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:36:58,749] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:01,349] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:01,351] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:05,436] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:05,436] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:08,751] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:08,752] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:11,353] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:11,354] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:15,439] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:15,442] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:18,755] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:18,758] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:21,355] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:21,356] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:25,444] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:25,446] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:28,761] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:28,761] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:31,361] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:31,361] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:35,448] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:35,449] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:38,766] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:38,766] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:41,363] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:41,365] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:45,453] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:45,453] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:48,771] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:48,772] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:51,369] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:51,371] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:55,459] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:55,459] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:37:58,777] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:37:58,777] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:01,373] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:01,373] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:05,465] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:05,465] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:08,782] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:08,783] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:11,378] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:11,379] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:15,471] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:15,471] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:18,787] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:18,788] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:21,384] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:21,385] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:25,476] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:25,476] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:28,796] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:28,797] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:31,386] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:31,387] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:35,481] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:35,482] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:38,802] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:38,802] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:41,388] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:41,389] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:45,487] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:45,487] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:48,807] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:48,808] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:51,394] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:51,395] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:55,491] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:55,492] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:38:58,809] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:38:58,810] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:01,398] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:01,398] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:05,497] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:05,497] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:08,815] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:08,816] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:11,399] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:11,400] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:15,500] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:15,501] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:18,820] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:18,821] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:21,403] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:21,405] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:25,506] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:25,507] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:28,824] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:28,825] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:31,409] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:31,409] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:35,512] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:35,513] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:38,829] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:38,830] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:41,413] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:41,414] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:45,516] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:45,517] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:48,834] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:48,835] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:51,416] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:51,417] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:55,519] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:55,519] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:39:58,839] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:39:58,840] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:01,419] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:01,419] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:05,522] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:05,523] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:08,845] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:08,846] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:11,421] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:11,422] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:15,526] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:15,527] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:18,850] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:18,850] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:21,423] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:21,424] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:25,530] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:25,531] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:28,851] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:28,852] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:31,427] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:31,428] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:35,536] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:35,537] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:38,854] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:38,855] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:41,429] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:41,430] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:45,540] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:45,540] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:48,857] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:48,858] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:51,435] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:51,436] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:55,542] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:55,542] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:40:58,862] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:40:58,862] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:01,440] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:01,440] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:05,546] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:05,547] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:08,867] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:08,867] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:11,442] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:11,443] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:15,548] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:15,549] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:18,872] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:18,873] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:21,446] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:21,447] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:25,552] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:25,552] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:28,874] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:28,874] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:31,452] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:31,453] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:35,555] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:35,555] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:38,879] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:38,880] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:41,459] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:41,460] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:45,562] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:45,564] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:48,885] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:48,886] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:51,465] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:51,466] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:55,568] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:55,569] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:41:58,887] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:41:58,888] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:01,467] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:01,468] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:05,574] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:05,574] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:08,889] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:08,889] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:11,469] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:11,470] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:15,578] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:15,579] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:18,894] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:18,895] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:21,475] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:21,475] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:25,581] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:25,582] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:28,898] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:28,899] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:31,478] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:31,479] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:35,587] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:35,587] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:38,902] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:38,903] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:41,481] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:41,482] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:45,593] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:45,595] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:48,903] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:48,904] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:51,485] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:51,486] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:55,599] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:55,600] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:42:58,907] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:42:58,908] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:01,490] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:01,491] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:05,603] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:05,604] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:08,913] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:08,914] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:11,493] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:11,495] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:15,610] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:15,611] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:18,916] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:18,916] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:21,498] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:21,499] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:25,613] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:25,614] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:28,922] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:28,923] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:31,505] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:31,508] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:35,616] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:35,617] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:38,927] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:38,927] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:41,509] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:41,509] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:45,618] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:45,619] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:48,930] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:48,931] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:51,512] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:51,512] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:55,624] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:55,625] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:43:58,935] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:43:58,935] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:01,517] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:01,518] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:05,627] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:05,627] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:08,938] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:08,939] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:11,522] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:11,523] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:15,629] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:15,629] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:18,941] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:18,942] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:21,526] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:21,527] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:25,631] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:25,632] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:28,947] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:28,947] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:31,532] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:31,534] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:35,637] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:35,638] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:38,948] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:38,949] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:41,538] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:41,539] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:45,643] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:45,644] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:48,953] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:48,954] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:51,543] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:51,544] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:55,648] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:55,650] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:44:58,958] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:44:58,959] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:01,549] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:01,550] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:05,656] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:05,656] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:08,962] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:08,963] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:11,554] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:11,555] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:15,661] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:15,661] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:18,966] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:18,967] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:21,560] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:21,561] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:25,666] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:25,667] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:28,972] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:28,973] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:31,566] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:31,567] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:35,669] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:35,671] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:38,974] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:38,974] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:41,572] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:41,572] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:45,676] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:45,677] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:48,980] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:48,981] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:51,577] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:51,577] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:55,684] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:55,686] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:45:58,986] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:45:58,988] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:01,581] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:01,582] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:05,690] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:05,691] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:08,990] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:08,991] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:11,585] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:11,585] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:15,696] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:15,697] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:18,994] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:18,995] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:21,590] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:21,591] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:25,700] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:25,701] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:29,001] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:29,002] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:31,596] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:31,597] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:35,704] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:35,705] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:39,007] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:39,007] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:41,602] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:41,602] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:45,706] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:45,706] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:49,009] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:49,010] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:51,605] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:51,606] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:55,711] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:55,712] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:46:59,011] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:46:59,012] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:01,610] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:01,611] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:05,715] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:05,716] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:09,012] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:09,013] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:11,612] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:11,613] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:15,720] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:15,721] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:19,015] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:19,016] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:21,618] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:21,619] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:25,726] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:25,727] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:29,019] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:29,019] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:31,621] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:31,622] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:35,732] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:35,733] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:39,022] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:39,023] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:41,624] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:41,624] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:45,735] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:45,736] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:49,026] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:49,027] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:51,625] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:51,626] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:55,741] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:55,743] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:47:59,030] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:47:59,031] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:01,630] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:01,631] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:05,744] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:05,745] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:09,035] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:09,035] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:11,637] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:11,638] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:15,750] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:15,751] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:19,041] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:19,043] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:21,643] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:21,644] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:25,752] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:25,753] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:29,046] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:29,048] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:31,648] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:31,648] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:35,757] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:35,757] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:39,049] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:39,049] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:41,654] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:41,654] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:45,763] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:45,763] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:49,054] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:49,054] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:51,658] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:51,659] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:55,769] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:55,770] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:48:59,057] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:48:59,057] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:01,659] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:01,660] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:05,774] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:05,775] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:09,062] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:09,063] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:11,665] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:11,665] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:15,778] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:15,780] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:19,066] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:19,066] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:21,667] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:21,668] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:25,784] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:25,785] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:29,071] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:29,072] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:31,672] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:31,673] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:35,790] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:35,793] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:39,075] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:39,075] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:41,677] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:41,678] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:45,797] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:45,798] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:49,077] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:49,077] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:51,681] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:51,682] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:55,802] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:55,803] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:49:59,081] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:49:59,082] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:01,687] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:01,688] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:05,805] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:05,807] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:09,085] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:09,086] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:11,692] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:11,693] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:15,811] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:15,812] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:19,088] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:19,089] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:21,697] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:21,697] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:25,814] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:25,815] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:29,094] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:29,095] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:31,699] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:31,701] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:35,817] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:35,817] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:39,097] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:39,097] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:41,706] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:41,707] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:45,820] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:45,822] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:49,100] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:49,101] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:51,710] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:51,711] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:55,825] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:55,826] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:50:59,105] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:50:59,106] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:01,712] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:01,713] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:05,828] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:05,829] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:09,110] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:09,110] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:11,713] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:11,714] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:15,834] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:15,836] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:19,111] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:19,112] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:21,719] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:21,720] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:25,841] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:25,846] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:29,115] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:29,129] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:31,725] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:31,728] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:35,851] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:35,851] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:39,134] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:39,135] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:41,733] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:41,733] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:45,857] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:45,858] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:49,139] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:49,140] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:51,739] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:51,740] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:55,861] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:55,862] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:51:59,145] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:51:59,145] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:52:01,745] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:52:01,748] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:52:05,867] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:52:05,867] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:52:09,147] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:52:09,149] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:52:11,753] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:52:11,753] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:52:15,868] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:52:15,869] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:52:19,154] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:52:19,155] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:52:21,757] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:52:21,757] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:52:25,872] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:52:25,872] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:52:29,160] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:52:29,160] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:52:29,788] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2021-04-19 11:52:29,788] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:327)
[2021-04-19 11:52:29,867] INFO Stopped http_8083@24934262{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:381)
[2021-04-19 11:52:29,882] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2021-04-19 11:52:29,888] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:344)
[2021-04-19 11:52:29,898] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:682)
[2021-04-19 11:52:29,913] INFO [Worker clientId=connect-1, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:656)
[2021-04-19 11:52:29,923] INFO Stopping task sink-connect-0 (org.apache.kafka.connect.runtime.Worker:836)
[2021-04-19 11:52:29,924] INFO Stopping connector source-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-19 11:52:29,924] INFO Stopping connector login-source-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-19 11:52:29,924] INFO Stopping connector signup-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-19 11:52:29,924] INFO Stopping connector sink-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-19 11:52:29,923] INFO Stopping task signup-connect-0 (org.apache.kafka.connect.runtime.Worker:836)
[2021-04-19 11:52:29,923] INFO Stopping task login-sink-connect-0 (org.apache.kafka.connect.runtime.Worker:836)
[2021-04-19 11:52:29,924] INFO Stopping connector login-sink-connect (org.apache.kafka.connect.runtime.Worker:387)
[2021-04-19 11:52:29,924] INFO Scheduled shutdown for WorkerConnector{id=signup-connect} (org.apache.kafka.connect.runtime.WorkerConnector:249)
[2021-04-19 11:52:29,924] INFO Scheduled shutdown for WorkerConnector{id=sink-connect} (org.apache.kafka.connect.runtime.WorkerConnector:249)
[2021-04-19 11:52:29,925] INFO Scheduled shutdown for WorkerConnector{id=login-source-connect} (org.apache.kafka.connect.runtime.WorkerConnector:249)
[2021-04-19 11:52:29,925] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:176)
[2021-04-19 11:52:29,925] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2021-04-19 11:52:29,925] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:176)
[2021-04-19 11:52:29,925] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2021-04-19 11:52:29,925] INFO Scheduled shutdown for WorkerConnector{id=login-sink-connect} (org.apache.kafka.connect.runtime.WorkerConnector:249)
[2021-04-19 11:52:29,925] INFO Scheduled shutdown for WorkerConnector{id=source-connect} (org.apache.kafka.connect.runtime.WorkerConnector:249)
[2021-04-19 11:52:29,925] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:317)
[2021-04-19 11:52:29,925] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:176)
[2021-04-19 11:52:29,925] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2021-04-19 11:52:29,930] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:161)
[2021-04-19 11:52:29,931] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:52:29,931] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:52:29,932] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:52:29,934] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:52:29,940] INFO [Consumer clientId=connector-consumer-login-sink-connect-0, groupId=connect-login-sink-connect] Revoke previously assigned partitions login_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2021-04-19 11:52:29,940] INFO [Consumer clientId=connector-consumer-login-sink-connect-0, groupId=connect-login-sink-connect] Member connector-consumer-login-sink-connect-0-03d39920-6234-4f96-8b88-3151f42ad8df sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-04-19 11:52:29,953] INFO Stopping task login-source-connect-0 (org.apache.kafka.connect.runtime.Worker:836)
[2021-04-19 11:52:29,953] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:317)
[2021-04-19 11:52:29,961] INFO Completed shutdown for WorkerConnector{id=login-sink-connect} (org.apache.kafka.connect.runtime.WorkerConnector:269)
[2021-04-19 11:52:29,961] INFO Completed shutdown for WorkerConnector{id=login-source-connect} (org.apache.kafka.connect.runtime.WorkerConnector:269)
[2021-04-19 11:52:29,961] INFO Completed shutdown for WorkerConnector{id=signup-connect} (org.apache.kafka.connect.runtime.WorkerConnector:269)
[2021-04-19 11:52:29,961] INFO Completed shutdown for WorkerConnector{id=sink-connect} (org.apache.kafka.connect.runtime.WorkerConnector:269)
[2021-04-19 11:52:29,961] INFO Stopping task source-connect-0 (org.apache.kafka.connect.runtime.Worker:836)
[2021-04-19 11:52:29,961] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:317)
[2021-04-19 11:52:29,962] INFO Completed shutdown for WorkerConnector{id=source-connect} (org.apache.kafka.connect.runtime.WorkerConnector:269)
[2021-04-19 11:52:29,962] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:52:29,962] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:52:29,962] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:52:29,972] INFO App info kafka.consumer for connector-consumer-login-sink-connect-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:52:29,975] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:324)
[2021-04-19 11:52:29,975] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:52:29,975] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:324)
[2021-04-19 11:52:29,975] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:52:29,975] INFO WorkerSourceTask{id=signup-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:52:29,975] INFO WorkerSourceTask{id=signup-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:52:29,975] INFO WorkerSourceTask{id=login-source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:52:29,975] INFO WorkerSourceTask{id=login-source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:52:29,975] INFO [Producer clientId=connector-producer-login-source-connect-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1205)
[2021-04-19 11:52:29,975] INFO [Producer clientId=connector-producer-signup-connect-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1205)
[2021-04-19 11:52:29,977] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:52:29,977] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:52:29,977] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:52:29,977] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:52:29,977] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:52:29,978] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:52:29,978] INFO App info kafka.producer for connector-producer-signup-connect-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:52:29,978] INFO App info kafka.producer for connector-producer-login-source-connect-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:52:30,023] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:324)
[2021-04-19 11:52:30,023] INFO Closing connection #1 to MySql (io.confluent.connect.jdbc.util.CachedConnectionProvider:108)
[2021-04-19 11:52:30,023] INFO WorkerSourceTask{id=source-connect-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:478)
[2021-04-19 11:52:30,023] INFO WorkerSourceTask{id=source-connect-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:495)
[2021-04-19 11:52:30,023] INFO [Producer clientId=connector-producer-source-connect-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1205)
[2021-04-19 11:52:30,026] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:52:30,026] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:52:30,026] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:52:30,027] INFO App info kafka.producer for connector-producer-source-connect-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:52:30,028] INFO [Worker clientId=connect-1, groupId=connect-cluster] Member connect-1-84424725-d91f-4a95-b4f9-b2bc31b3961c sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-04-19 11:52:30,028] WARN [Worker clientId=connect-1, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1010)
[2021-04-19 11:52:30,028] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:52:30,028] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:52:30,028] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:52:30,029] INFO App info kafka.connect for connect-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:52:30,029] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:170)
[2021-04-19 11:52:30,029] INFO [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1205)
[2021-04-19 11:52:30,030] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:52:30,030] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:52:30,030] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:52:30,030] INFO App info kafka.producer for producer-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:52:30,030] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:52:30,030] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:52:30,030] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:52:30,031] INFO App info kafka.consumer for consumer-connect-cluster-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:52:30,031] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:196)
[2021-04-19 11:52:30,031] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:285)
[2021-04-19 11:52:30,031] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:170)
[2021-04-19 11:52:30,031] INFO [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1205)
[2021-04-19 11:52:30,031] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:52:30,031] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:52:30,031] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:52:30,032] INFO App info kafka.producer for producer-3 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:52:30,032] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:52:30,032] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:52:30,032] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:52:30,032] INFO App info kafka.consumer for consumer-connect-cluster-3 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:52:30,032] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:196)
[2021-04-19 11:52:30,032] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:287)
[2021-04-19 11:52:30,032] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:209)
[2021-04-19 11:52:30,033] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:134)
[2021-04-19 11:52:30,033] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:170)
[2021-04-19 11:52:30,033] INFO [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1205)
[2021-04-19 11:52:30,034] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:52:30,034] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:52:30,034] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:52:30,035] INFO App info kafka.producer for producer-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:52:30,036] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:52:30,036] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:52:30,036] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:52:30,036] INFO App info kafka.consumer for consumer-connect-cluster-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:52:30,036] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:196)
[2021-04-19 11:52:30,036] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:136)
[2021-04-19 11:52:30,036] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-04-19 11:52:30,036] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-04-19 11:52:30,036] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-04-19 11:52:30,037] INFO App info kafka.connect for 218.38.137.28:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-04-19 11:52:30,037] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:230)
[2021-04-19 11:52:30,043] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:300)
[2021-04-19 11:52:30,048] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:702)
[2021-04-19 11:52:30,048] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
